{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "GCN_BERT_attention_kfold.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJdyXXq9Kewe",
        "colab_type": "text"
      },
      "source": [
        "## Start"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "z6TuFfcvZyno",
        "outputId": "e462fb09-3ff7-4df8-e5da-f84ac90224d2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "LWFFLdrJZbNq",
        "outputId": "7488da82-e1ae-4d9f-9e29-120d98f978cd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 156
        }
      },
      "source": [
        "# ! pip install transformers==2.2.2 -q\n",
        "! pip install transformers -q\n",
        "! pip install dgl-cu100 -q\n",
        "! pip install word2vec -q"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[K     |████████████████████████████████| 573kB 2.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 3.7MB 42.8MB/s \n",
            "\u001b[K     |████████████████████████████████| 890kB 40.6MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.7MB/s \n",
            "\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[K     |████████████████████████████████| 16.8MB 188kB/s \n",
            "\u001b[K     |████████████████████████████████| 71kB 2.3MB/s \n",
            "\u001b[?25h  Building wheel for word2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9W8iuy5iZbN0",
        "outputId": "d5ff0823-a713-4d24-e4f9-12fdf01727ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "source": [
        "import csv\n",
        "import re\n",
        "import pandas as pd\n",
        "from pathlib import Path\n",
        "import matplotlib.cm as cm\n",
        "from fastai import *\n",
        "from fastai.text import *\n",
        "from fastai.callbacks import *\n",
        "from fastai.metrics import *\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from pathlib import Path\n",
        "from typing import *\n",
        "\n",
        "import torch\n",
        "import torch.optim as optim\n",
        "import dgl\n",
        "import word2vec"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "DGL backend not selected or invalid.  Assuming PyTorch for now.\n",
            "Using backend: pytorch\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Setting the default backend to \"pytorch\". You can change it in the ~/.dgl/config.json file or export the DGLBACKEND environment variable.  Valid options are: pytorch, mxnet, tensorflow (all lowercase)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "WJUOCfwJ7nG7",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "bDcJAbWQmWmW",
        "colab": {}
      },
      "source": [
        "seed = 42\n",
        "\n",
        "# python RNG\n",
        "import random\n",
        "random.seed(seed)\n",
        "\n",
        "# pytorch RNGs\n",
        "import torch\n",
        "torch.manual_seed(seed)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "# numpy RNG\n",
        "import numpy as np\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "Pfkl3wOmaRkt",
        "outputId": "dc44e2d4-8631-44f9-d462-d85724656263",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 660
        }
      },
      "source": [
        "import os\n",
        "os.chdir('/gdrive/My Drive/DEFINITION EXTRACTION/Definition')\n",
        "! ls"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            " AutoTransfomer_attention.ipynb\n",
            " AutoTransfomer_attention_kfold_data_cased_symbols.ipynb\n",
            " AutoTransfomer_attention_kfold_data_cased_symbols_no_tuning.ipynb\n",
            " AutoTransfomer_attention_kfold_data_uncased_symbols.ipynb\n",
            " AutoTransfomer_attention_kfold_data_uncased_symbols_no_tuning.ipynb\n",
            " AutoTransfomer_attention_kfold.ipynb\n",
            " AutoTransfomer_attention_kfold_no_tuning.ipynb\n",
            " AutoTransfomer.ipynb\n",
            " bert_cached_lm_510_deft.test.raw\n",
            " bert_cached_lm_510_deft.train.raw\n",
            " bert-fastai.ipynb\n",
            " bert_ft\n",
            " BertTransfomer_attention.ipynb\n",
            " bertviz\n",
            " cnn_lstm_series_dep.ipynb\n",
            "'Copy of AutoTransfomer_attention_kfold_data_cased_symbols.ipynb'\n",
            "'Copy of AutoTransfomer_attention_kfold_data_uncased_symbols.ipynb'\n",
            "'Copy of GCN_BERT_attention_kfold.ipynb'\n",
            "'Copy of W00.csv'\n",
            " data_processing.ipynb\n",
            " deft.test.raw\n",
            " deft.train.raw\n",
            " End2End.ipynb\n",
            " lstm_attn.ipynb\n",
            " models\n",
            " runs\n",
            " train_lm.py\n",
            " VisualizeTransfomer.ipynb\n",
            " W00_BERT.ipynb\n",
            " WCL_cased_symbols.csv\n",
            " WCL_data1.csv\n",
            " WCL_data1.gsheet\n",
            " WCL_data2.csv\n",
            " WCL_data2.gsheet\n",
            " WCL_data_preprocessed.csv\n",
            " WCL_data_preprocessed.gsheet\n",
            " WOO_p.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "17X4qG7RZbN-",
        "colab": {}
      },
      "source": [
        "model_name=\"bert-base-cased\"\n",
        "# model_name=\"roberta-base\"\n",
        "# model_name=\"xlnet-base-cased\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHkuwclg5EFy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TEXT_COL = 'Psentence'\n",
        "Y_COL = 'label'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxp-rwB2jm4_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import re\n",
        "def multi_replace(chars_to_replace, char_to_place, from_string):\n",
        "    for char in chars_to_replace:\n",
        "        from_string = from_string.replace(char,char_to_place)\n",
        "    return from_string\n",
        "\n",
        "def preprocessing(sentence):\n",
        "    remove_punct = multi_replace(',“”’.-{}[]()=+_!@#$%^&*<>?/|\\\\~`:;\"','',sentence)\n",
        "    return remove_punct\n",
        "\n",
        "def load_data(file):\n",
        "    df = pd.read_csv(file)\n",
        "    # removing initial numbers\n",
        "    df[TEXT_COL] = df[TEXT_COL].apply(lambda x : re.findall('^\\s*\\d*\\s*\\.?\\s*(.*)',x)[0])\n",
        "    # preprocessing\n",
        "    # df[TEXT_COL] = df[TEXT_COL].apply(preprocessing)\n",
        "    return df\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9Ad9AScmzi00",
        "outputId": "90a77ece-02c0-4e3d-ab04-c0a8ec11a51f",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 147
        }
      },
      "source": [
        "merged = load_data('WCL_cased_symbols.csv')\n",
        "merged.head(2)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Psentence</th>\n",
              "      <th>Length</th>\n",
              "      <th>Dep1</th>\n",
              "      <th>Dep2</th>\n",
              "      <th>DepLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A Pianist   is  a person who plays the piano.</td>\n",
              "      <td>9</td>\n",
              "      <td>Pianist is is is person person plays plays piano</td>\n",
              "      <td>A Pianist person . a plays who piano the</td>\n",
              "      <td>nsubj ROOT ROOT ROOT attr attr relcl relcl dobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Pingala has a sunlike nature and male energy.</td>\n",
              "      <td>8</td>\n",
              "      <td>has has has nature nature nature nature energy</td>\n",
              "      <td>Pingala nature . a sunlike and energy male</td>\n",
              "      <td>ROOT ROOT ROOT dobj dobj dobj dobj conj</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                         DepLabel\n",
              "0      1  ...  nsubj ROOT ROOT ROOT attr attr relcl relcl dobj\n",
              "1      0  ...          ROOT ROOT ROOT dobj dobj dobj dobj conj\n",
              "\n",
              "[2 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_Cggr4LVl1Le",
        "colab": {}
      },
      "source": [
        "def seq_len(row):\n",
        "  return len(row[TEXT_COL].split())\n",
        "\n",
        "merged['Length'] = merged.apply(seq_len, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oj6xgU_Nl30d",
        "outputId": "e637d32d-c3e7-406d-b041-a4a9d85dd011",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "merged = merged[merged['Length']>4]\n",
        "merged.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(4679, 6)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "steUgP-kdfwV",
        "colab_type": "code",
        "outputId": "cc2ca92c-cd68-44cf-83ab-280e4a86bbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        }
      },
      "source": [
        "merged.head(3)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>label</th>\n",
              "      <th>Psentence</th>\n",
              "      <th>Length</th>\n",
              "      <th>Dep1</th>\n",
              "      <th>Dep2</th>\n",
              "      <th>DepLabel</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>A Pianist   is  a person who plays the piano.</td>\n",
              "      <td>9</td>\n",
              "      <td>Pianist is is is person person plays plays piano</td>\n",
              "      <td>A Pianist person . a plays who piano the</td>\n",
              "      <td>nsubj ROOT ROOT ROOT attr attr relcl relcl dobj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>Pingala has a sunlike nature and male energy.</td>\n",
              "      <td>8</td>\n",
              "      <td>has has has nature nature nature nature energy</td>\n",
              "      <td>Pingala nature . a sunlike and energy male</td>\n",
              "      <td>ROOT ROOT ROOT dobj dobj dobj dobj conj</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>It's center is the city of Qorveh which is loc...</td>\n",
              "      <td>16</td>\n",
              "      <td>'s 's is is city city city of located located ...</td>\n",
              "      <td>It center city . the of located Qorveh which i...</td>\n",
              "      <td>ROOT ROOT ROOT ROOT attr attr attr prep relcl ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   label  ...                                           DepLabel\n",
              "0      1  ...    nsubj ROOT ROOT ROOT attr attr relcl relcl dobj\n",
              "1      0  ...            ROOT ROOT ROOT dobj dobj dobj dobj conj\n",
              "2      0  ...  ROOT ROOT ROOT ROOT attr attr attr prep relcl ...\n",
              "\n",
              "[3 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KoIuR9xTQpLz",
        "colab_type": "text"
      },
      "source": [
        "## GCN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIwAE3NhQokQ",
        "colab_type": "code",
        "outputId": "307b3caf-b0c8-4569-eadb-244eb0bb24c9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "class DataHelper(object):\n",
        "    def __init__(self, df, mode='train', vocab=None):\n",
        "        self.mode = mode\n",
        "        \n",
        "        self.df = df\n",
        "        if self.mode=='train':\n",
        "          content, label = self.get_content()\n",
        "          self.label = self.label_to_onehot(label)\n",
        "\n",
        "        else:\n",
        "          content = self.get_content()\n",
        "        \n",
        "        if vocab is None:\n",
        "            self.vocab = []\n",
        "            try:\n",
        "                print(f'File found')\n",
        "                self.get_vocab()\n",
        "            except FileNotFoundError:\n",
        "                self.build_vocab(content, min_count=5)\n",
        "        else:\n",
        "            self.vocab = vocab\n",
        "\n",
        "        self.d = dict(zip(self.vocab, range(len(self.vocab))))\n",
        "        self.rev_d = { v:k for k,v in self.d.items()}\n",
        "        self.content = [list(map(lambda x: self.word2id(x), doc.split(' '))) for doc in content]\n",
        "        self.lengths = [[len(s)] for s in self.content]\n",
        "        self.content = pad_sequences(self.content, maxlen=64, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "\n",
        "\n",
        "    def label_to_onehot(self, label_str):\n",
        "      return np.array(self.df[Y_COL])\n",
        "        \n",
        "    def get_content(self):\n",
        "        if self.mode=='train':\n",
        "          return list(self.df[TEXT_COL]), list(self.df[Y_COL])\n",
        "        else:\n",
        "          return list(self.df[TEXT_COL])\n",
        "\n",
        "    def word2id(self, word):\n",
        "        try:\n",
        "            result = self.d[word]\n",
        "        except KeyError:\n",
        "            result = self.d['UNK']\n",
        "        return result\n",
        "\n",
        "    def get_vocab(self):\n",
        "        with open('vocab-5.txt') as f:\n",
        "            vocab = f.read()\n",
        "            self.vocab = vocab.split('\\n')\n",
        "\n",
        "    def build_vocab(self, content, min_count=10):\n",
        "        vocab = []\n",
        "        for c in content:\n",
        "            words = c.split(' ')\n",
        "            for word in words:\n",
        "                if word not in vocab:\n",
        "                    vocab.append(word)\n",
        "        freq = dict(zip(vocab, [0 for i in range(len(vocab))]))\n",
        "        for c in content:\n",
        "            words = c.split(' ')\n",
        "            for word in words:\n",
        "                freq[word] += 1\n",
        "        results = []\n",
        "        for word in freq.keys():\n",
        "            if freq[word] < min_count:\n",
        "                continue\n",
        "            else:\n",
        "                results.append(word)\n",
        "        results.insert(0, 'UNK')\n",
        "        with open('vocab.txt', 'w') as f:\n",
        "            f.write('\\n'.join(results))\n",
        "        self.vocab = results\n",
        "\n",
        "    def count_word_freq(self, content):\n",
        "        freq = dict(zip(self.vocab, [0 for i in range(len(self.vocab))]))\n",
        "        for c in content:\n",
        "            words = c.split(' ')\n",
        "            for word in words:\n",
        "                freq[word] += 1\n",
        "        with open('freq.csv', 'w') as f:\n",
        "            writer = csv.writer(f)\n",
        "            results = list(zip(freq.keys(), freq.values()))\n",
        "            writer.writerows(results)\n",
        "\n",
        "    def batch_iter(self, batch_size, num_epoch):\n",
        "        for i in range(num_epoch):\n",
        "            num_per_epoch = int(len(self.content) / batch_size)\n",
        "            for batch_id in range(num_per_epoch):\n",
        "                start = batch_id * batch_size\n",
        "                end = min((batch_id + 1) * batch_size, len(self.content))\n",
        "                content = self.content[start:end]\n",
        "                label = self.label[start:end]\n",
        "                yield (content), torch.LongTensor(label).cuda(), i\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Acdc6yLSb3dp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df = merged"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evBYVJxYQ-JJ",
        "colab_type": "code",
        "outputId": "82ad867d-d17f-46dc-ada4-0893836d43c7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "source": [
        "train_data_helper = DataHelper(merged, mode='train')\n",
        "test_data_helper = DataHelper(merged, mode='test')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "File found\n",
            "File found\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "ZI5qRserOi64"
      },
      "source": [
        "## Transformer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "8TBbnX8TZbOF",
        "outputId": "9019fc4c-8b45-40b7-a0d1-659206586a27",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        " %tensorflow_version 1.x \n",
        "from transformers import BertTokenizer, GPT2Tokenizer\n",
        "from transformers import BertForSequenceClassification,  AutoModelForSequenceClassification\n",
        "\n",
        "from transformers import BertPreTrainedModel, BertModel\n",
        "\n",
        "tokenizer = BertTokenizer.from_pretrained(model_name, output_attentions=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow is already loaded. Please restart the runtime to change versions.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "uqMNSbhMwCeA"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EJtATahguhJR",
        "colab": {}
      },
      "source": [
        "from keras.preprocessing.sequence import pad_sequences\n",
        "MAX_LEN = 64\n",
        "\n",
        "def tokenise_pad(df):\n",
        "  X = [tokenizer.encode(x, add_special_tokens=True) for x in df[TEXT_COL]]\n",
        "  X = pad_sequences(X, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "  return X\n",
        "\n",
        "\n",
        "X = tokenise_pad(merged)\n",
        "X_test = tokenise_pad(test_df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqO4Ng29FpZp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def return_attention_masks(X):\n",
        "  attention_masks = []\n",
        "  for seq in X:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "  attention_masks = np.array(attention_masks)  \n",
        "  return attention_masks"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nDoz1nrcF6xb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "attention_masks = return_attention_masks(X)\n",
        "test_attention_masks = return_attention_masks(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "oT3_hc6Sw0tw",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "NmQYwCcWxDQT",
        "colab": {}
      },
      "source": [
        "y = np.array(merged[Y_COL])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "02ZqMPeySpGS",
        "colab_type": "text"
      },
      "source": [
        "## Models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A6iNu714VUUK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def cal_PMI(helper, window_size=20):\n",
        "    content, _ = helper.get_content()\n",
        "    pair_count_matrix = np.zeros((len(helper.vocab), len(helper.vocab)), dtype=int)\n",
        "    word_count =np.zeros(len(helper.vocab), dtype=int)\n",
        "\n",
        "    for sentence in content:\n",
        "        sentence = sentence.split(' ')\n",
        "        for i, word in enumerate(sentence):\n",
        "            try:\n",
        "                word_count[helper.d[word]] += 1\n",
        "            except KeyError:\n",
        "                continue\n",
        "            start_index = max(0, i - window_size)\n",
        "            end_index = min(len(sentence), i + window_size)\n",
        "            for j in range(start_index, end_index):\n",
        "                if i == j:\n",
        "                    continue\n",
        "                else:\n",
        "                    target_word = sentence[j]\n",
        "                    try:\n",
        "                        pair_count_matrix[helper.d[word], helper.d[target_word]] += 1\n",
        "                    except KeyError:\n",
        "                        continue\n",
        "\n",
        "    total_count = np.sum(word_count)\n",
        "    word_count = word_count / total_count\n",
        "    pair_count_matrix = pair_count_matrix / total_count\n",
        "\n",
        "    pmi_matrix = np.zeros((len(helper.vocab), len(helper.vocab)), dtype=float)\n",
        "    for i in range(len(helper.vocab)):\n",
        "        for j in range(len(helper.vocab)):\n",
        "            pmi_matrix[i, j] = np.log(\n",
        "                pair_count_matrix[i, j] / (word_count[i] * word_count[j])\n",
        "            )\n",
        "\n",
        "    pmi_matrix = np.nan_to_num(pmi_matrix)\n",
        "\n",
        "    pmi_matrix = np.maximum(pmi_matrix, 0.0)\n",
        "\n",
        "    edges_weights = [0.0]\n",
        "    count = 1\n",
        "    edges_mappings = np.zeros((len(helper.vocab), len(helper.vocab)), dtype=int)\n",
        "    for i in range(len(helper.vocab)):\n",
        "        for j in range(len(helper.vocab)):\n",
        "            if pmi_matrix[i, j] != 0:\n",
        "                edges_weights.append(pmi_matrix[i, j])\n",
        "                edges_mappings[i, j] = count\n",
        "                count += 1\n",
        "\n",
        "    edges_weights = np.array(edges_weights)\n",
        "\n",
        "    edges_weights = edges_weights.reshape(-1, 1)\n",
        "    # print(edges_weights.shape)\n",
        "    edges_weights = torch.Tensor(edges_weights)\n",
        "\n",
        "    return edges_weights, edges_mappings, count\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZsx152OT82_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gcn_msg(edge):\n",
        "    return {'m': edge.src['h'], 'w': edge.data['w']}\n",
        "\n",
        "\n",
        "def gcn_reduce(node):\n",
        "    w = node.mailbox['w']\n",
        "\n",
        "    new_hidden = torch.mul(w, node.mailbox['m'])\n",
        "\n",
        "    new_hidden,_ = torch.max(new_hidden, 1)\n",
        "\n",
        "    node_eta = torch.sigmoid(node.data['eta'])\n",
        "    # node_eta = F.leaky_relu(node.data['eta'])\n",
        "\n",
        "    # new_hidden = node_eta * node.data['h'] + (1 - node_eta) * new_hidden\n",
        "    # print(new_hidden.shape)\n",
        "\n",
        "    return {'h': new_hidden}\n",
        "\n",
        "\n",
        "class GCNModel(torch.nn.Module):\n",
        "    def __init__(self,\n",
        "                 hidden_size_node,\n",
        "                 vocab,\n",
        "                 n_gram,\n",
        "                 edges_num,\n",
        "                 edges_matrix,\n",
        "                 max_length=350,\n",
        "                 trainable_edges=True,\n",
        "                 pmi=None,\n",
        "                 cuda=True\n",
        "                 ):\n",
        "        super(GCNModel, self).__init__()\n",
        "\n",
        "        self.is_cuda = cuda\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        self.seq_edge_w = torch.nn.Embedding(edges_num, 1)\n",
        "        print(edges_num)\n",
        "        print(pmi.shape)\n",
        "\n",
        "        self.node_hidden = torch.nn.Embedding(len(vocab), hidden_size_node)\n",
        "        \n",
        "        self.seq_edge_w = torch.nn.Embedding.from_pretrained(pmi, freeze=True)\n",
        "            \n",
        "        self.edges_num = edges_num\n",
        "        if trainable_edges:\n",
        "            self.seq_edge_w = torch.nn.Embedding.from_pretrained(torch.ones(edges_num, 1), freeze=False)\n",
        "        else:\n",
        "            self.seq_edge_w = torch.nn.Embedding.from_pretrained(pmi, freeze=True)\n",
        "\n",
        "        self.hidden_size_node = hidden_size_node\n",
        "\n",
        "        self.node_hidden.weight.data.copy_(torch.tensor(self.load_word2vec('glove.6B.200d.vec.txt')))\n",
        "        self.node_hidden.weight.requires_grad = True\n",
        "\n",
        "        self.len_vocab = len(vocab)\n",
        "\n",
        "        self.ngram = n_gram\n",
        "        self.d = dict(zip(self.vocab, range(len(self.vocab))))\n",
        "        self.max_length = max_length\n",
        "        self.edges_matrix = edges_matrix\n",
        "\n",
        "        self.dropout = torch.nn.Dropout(0.5)\n",
        "        self.activation = torch.nn.ReLU()\n",
        "\n",
        "        \n",
        "\n",
        "    def word2id(self, word):\n",
        "        try:\n",
        "            result = self.d[word]\n",
        "        except KeyError:\n",
        "            result = self.d['UNK']\n",
        "\n",
        "        return result\n",
        "\n",
        "    def load_word2vec(self, word2vec_file):\n",
        "        model = word2vec.load(word2vec_file)\n",
        "        embedding_matrix = []\n",
        "        for word in self.vocab:\n",
        "            try:\n",
        "                embedding_matrix.append(model[word])\n",
        "            except KeyError:\n",
        "                # print(word)\n",
        "                embedding_matrix.append(model['the'])\n",
        "        embedding_matrix = np.array(embedding_matrix)\n",
        "        return embedding_matrix\n",
        "\n",
        "    \n",
        "\n",
        "    def add_seq_edges(self, doc_ids: list, old_to_new: dict):\n",
        "        edges = []\n",
        "        old_edge_id = []\n",
        "        for index, src_word_old in enumerate(doc_ids):\n",
        "            src = old_to_new[int(src_word_old.item())]\n",
        "            for i in range(max(0, index - self.ngram), min(index + self.ngram + 1, len(doc_ids))):\n",
        "                dst_word_old = doc_ids[i].item()\n",
        "                dst = old_to_new[dst_word_old]\n",
        "\n",
        "                # - first connect the new sub_graph\n",
        "                edges.append([src, dst])\n",
        "                # - then get the hidden from parent_graph\n",
        "                old_edge_id.append(self.edges_matrix[src_word_old, dst_word_old])\n",
        "\n",
        "            # self circle\n",
        "            edges.append([src, src])\n",
        "            old_edge_id.append(self.edges_matrix[src_word_old, src_word_old])\n",
        "        return edges, old_edge_id\n",
        "\n",
        "    def seq_to_graph(self, doc_ids: list, doc_length) -> dgl.DGLGraph():\n",
        "        doc_ids = doc_ids[0:doc_length]\n",
        "        if len(doc_ids) > self.max_length:\n",
        "            doc_ids = doc_ids[:self.max_length]\n",
        "        local_vocab = set(doc_ids)\n",
        "\n",
        "        old_to_new = {}\n",
        "        for i,j in enumerate(local_vocab):\n",
        "          old_to_new[j.item()] = i\n",
        "        # old_to_new = dict(zip(local_vocab, range(len(local_vocab))))\n",
        "\n",
        "        # print(old_to_new)\n",
        "\n",
        "        if self.is_cuda:\n",
        "            local_vocab = torch.tensor(list(local_vocab)).cuda()\n",
        "        else:\n",
        "            local_vocab = torch.tensor(list(local_vocab))\n",
        "\n",
        "        sub_graph = dgl.DGLGraph()\n",
        "\n",
        "        sub_graph.add_nodes(len(local_vocab))\n",
        "        local_node_hidden = self.node_hidden(local_vocab)\n",
        "\n",
        "        sub_graph.ndata['h'] = local_node_hidden\n",
        "\n",
        "        seq_edges, seq_old_edges_id = self.add_seq_edges(doc_ids, old_to_new)\n",
        "\n",
        "        edges, old_edge_id = [], []\n",
        "        \n",
        "        edges.extend(seq_edges)\n",
        "\n",
        "        old_edge_id.extend(seq_old_edges_id)\n",
        "\n",
        "        if self.is_cuda:\n",
        "            old_edge_id = torch.LongTensor(old_edge_id).cuda()\n",
        "        else:\n",
        "            old_edge_id = torch.LongTensor(old_edge_id)\n",
        "\n",
        "        srcs, dsts = zip(*edges)\n",
        "        sub_graph.add_edges(srcs, dsts)\n",
        "        try:\n",
        "            seq_edges_w = self.seq_edge_w(old_edge_id)\n",
        "        except RuntimeError:\n",
        "            print(old_edge_id)\n",
        "        sub_graph.edata['w'] = seq_edges_w\n",
        "\n",
        "        return sub_graph\n",
        "\n",
        "    def forward(self, doc_ids, doc_lengths):\n",
        "        sub_graphs = [self.seq_to_graph(doc, length) for doc, length in zip(doc_ids, doc_lengths)]\n",
        "\n",
        "        batch_graph = dgl.batch(sub_graphs)\n",
        "\n",
        "        batch_graph.update_all(\n",
        "            message_func=dgl.function.src_mul_edge('h', 'w', 'weighted_message'),\n",
        "            reduce_func=dgl.function.max('weighted_message', 'h')\n",
        "        )\n",
        "\n",
        "        h1 = dgl.sum_nodes(batch_graph, feat='h')\n",
        "        drop1 = self.dropout(h1)\n",
        "        act1 = self.activation(drop1)\n",
        "        # l = self.Linear(act1)\n",
        "        return act1\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mwbhkwuDSoUu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertFeature(BertPreTrainedModel):\n",
        "    def __init__(self, config):\n",
        "        super().__init__(config)\n",
        "        self.bert = BertModel(config)\n",
        "        self.init_weights()\n",
        "        self.features = config.hidden_size\n",
        "\n",
        "    def forward(\n",
        "        self,\n",
        "        input_ids=None,\n",
        "        attention_mask=None,\n",
        "        token_type_ids=None,\n",
        "        position_ids=None,\n",
        "        head_mask=None,\n",
        "        inputs_embeds=None,\n",
        "        labels=None,\n",
        "    ):\n",
        "\n",
        "            bert_outputs = self.bert(\n",
        "              input_ids,\n",
        "              attention_mask=attention_mask,\n",
        "              token_type_ids=token_type_ids,\n",
        "              position_ids=position_ids,\n",
        "              head_mask=head_mask,\n",
        "              inputs_embeds=inputs_embeds,\n",
        "            )\n",
        "            pooled_output = bert_outputs[1]\n",
        "\n",
        "            return pooled_output"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EiVHnVrSBBNn",
        "colab_type": "text"
      },
      "source": [
        "## Main Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru0VPF2dat-F",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BertGCN(nn.Module):\n",
        "  def __init__(self, hidden, vocabulary, n_grams, edges_mappings, edges_weights, count, num_classes, dropout_prob):\n",
        "    super(BertGCN, self).__init__()\n",
        "    self.bert = BertFeature.from_pretrained('bert-base-cased', output_attentions=False)\n",
        "    self.gcn = GCNModel(hidden_size_node = hidden,\n",
        "                            vocab = vocabulary,\n",
        "                            n_gram = n_grams,\n",
        "                            edges_matrix = edges_mappings,\n",
        "                            edges_num = count,\n",
        "                            trainable_edges = True, \n",
        "                            pmi = edges_weights, \n",
        "                            cuda = True\n",
        "                            )\n",
        "    self.num_classes = num_classes\n",
        "    self.dropout = nn.Dropout(dropout_prob)\n",
        "    self.bn1 = nn.BatchNorm1d(self.bert.features)\n",
        "    self.relu1 = torch.nn.ReLU()\n",
        "    self.relu2 = torch.nn.ReLU()\n",
        "    \n",
        "    self.bn2 = nn.BatchNorm1d(hidden)\n",
        "    \n",
        "    self.classifier = nn.Linear(self.bert.features + hidden, self.num_classes)\n",
        "\n",
        "  def forward(self, input_ids, attention_mask, input_gcn, sent_len, labels=None):\n",
        "    bert_out = self.bert(input_ids, attention_mask)\n",
        "    gcn_out = self.gcn(input_gcn, sent_len)\n",
        "\n",
        "    # return bert_out, gcn_out\n",
        "\n",
        "    # bert_out = self.bn1(bert_out)\n",
        "    # gcn_out = self.bn2(gcn_out)\n",
        "    \n",
        "    # bert_out = self.relu1(bert_out)\n",
        "    # gcn_out = self.relu2(gcn_out)\n",
        "\n",
        "    out = torch.cat((bert_out, gcn_out), 1)\n",
        "    # pooled_output = self.dropout(out)\n",
        "    logits = self.classifier(out)\n",
        "\n",
        "    outputs = (logits,)\n",
        "\n",
        "    if labels is not None:\n",
        "        if self.num_classes == 1:\n",
        "            loss_fct = MSELoss()\n",
        "            loss = loss_fct(logits.view(-1), labels.view(-1))\n",
        "        else:\n",
        "            loss_fct = torch.nn.CrossEntropyLoss()\n",
        "            loss = loss_fct(logits.view(-1, self.num_classes), labels.view(-1))\n",
        "        outputs = (loss,) + outputs\n",
        "    return outputs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WrR6bjn8du_M",
        "colab_type": "text"
      },
      "source": [
        "## DEBUG"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhCtvR35VZ0T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "edges_weights, edges_mappings, count = cal_PMI(train_data_helper, 5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7WXHTWvdw7N",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# model = BertGCN(hidden = 200,\n",
        "#                 vocabulary = train_data_helper.vocab,\n",
        "#                 n_grams = 5,\n",
        "#                 edges_mappings = edges_mappings,\n",
        "#                 edges_weights = edges_weights, \n",
        "#                 count = count, \n",
        "#                 num_classes = 2, \n",
        "#                 dropout_prob = 0.3\n",
        "#                 )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "qCrL_HHYxQwa"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "vs29Zck60rpB",
        "outputId": "a520083c-8cde-4b12-f58f-018e6813d381",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
        "device"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda', index=0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "9mqC5yTxyV3-",
        "colab": {}
      },
      "source": [
        "from sklearn.utils.extmath import softmax\n",
        "from sklearn.metrics import classification_report, f1_score\n",
        "BATCH_SIZE = 32\n",
        "\n",
        "\n",
        "def flat_accuracy(preds, labels):\n",
        "    preds = softmax(preds)\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n",
        "\n",
        "\n",
        "def flat_f1(preds, labels):\n",
        "    preds = softmax(preds)\n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "    return f1_score(labels_flat, pred_flat)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KXZgwyjq0DMw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_gcn = train_data_helper.content\n",
        "X_len = train_data_helper.lengths\n",
        "X_test_gcn = test_data_helper.content\n",
        "X_test_len = test_data_helper.lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "knqd-QH4x-Oy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_gcn = np.array(X_gcn)\n",
        "X_test_gcn = np.array(X_test_gcn)\n",
        "\n",
        "X_len = np.array(X_len)\n",
        "X_test_len = np.array(X_test_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f89BreE1-ma3",
        "colab_type": "code",
        "outputId": "54be1871-73d0-46ce-ab41-27077675b556",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_test.shape, X_test_gcn.shape, test_attention_masks.shape, X_test_len.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4679, 64), (4679, 64), (4679, 64), (4679, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9GScsKOEiUT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_test = torch.tensor(X_test)\n",
        "X_test_masks = torch.tensor(test_attention_masks)\n",
        "X_test_gcn = torch.tensor(X_test_gcn)\n",
        "X_test_len = torch.tensor(X_test_len)\n",
        "\n",
        "test_data = TensorDataset(X_test, X_test_masks, X_test_gcn, X_test_len)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d1IX4_ZwHzR3",
        "colab_type": "text"
      },
      "source": [
        "### Loop"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "EZww_KS_w93w",
        "outputId": "02e3f8fe-a205-42c1-df43-3f3379808783",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "from tqdm import tqdm\n",
        "import sys\n",
        "\n",
        "auto_model = None\n",
        "\n",
        "results = pd.DataFrame()\n",
        "\n",
        "S = []\n",
        "\n",
        "nfolds = 10\n",
        "\n",
        "kf = StratifiedKFold(nfolds, shuffle=True, random_state=2018)\n",
        "for f,(tr, val) in enumerate(kf.split(X, y)):\n",
        "    print(f'--------------------------------------------------------------------------------Fold # {f}--------------------------------------------------------------------')\n",
        "\n",
        "    X_train, X_val = X[tr], X[val]\n",
        "    y_train, y_val = y[tr], y[val]\n",
        "    X_train_gcn, X_val_gcn = X_gcn[tr], X_gcn[val]\n",
        "    X_train_masks, X_val_masks = attention_masks[tr], attention_masks[val]\n",
        "    X_train_len, X_val_len = X_len[tr], X_len[val]\n",
        "                                         \n",
        "    # Convert all of our data into torch tensors, the required datatype for our model\n",
        "    X_train = torch.tensor(X_train)\n",
        "    X_val = torch.tensor(X_val)\n",
        "\n",
        "    y_train = torch.tensor(y_train)\n",
        "    y_val = torch.tensor(y_val)\n",
        "\n",
        "    X_train_masks = torch.tensor(X_train_masks)\n",
        "    X_val_masks = torch.tensor(X_val_masks)\n",
        "\n",
        "    X_train_gcn = torch.tensor(X_train_gcn)\n",
        "    X_val_gcn = torch.tensor(X_val_gcn)\n",
        "\n",
        "    X_train_len = torch.tensor(X_train_len)\n",
        "    X_val_len = torch.tensor(X_val_len)\n",
        "\n",
        "    \n",
        "    # Create an iterator of data with torch DataLoader \n",
        "    train_data = TensorDataset(X_train, X_train_masks, X_train_gcn, X_train_len, y_train)\n",
        "    train_sampler = SequentialSampler(train_data)\n",
        "    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "    validation_data = TensorDataset(X_val, X_val_masks, X_val_gcn, X_val_len, y_val)\n",
        "    validation_sampler = SequentialSampler(validation_data)\n",
        "    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "\n",
        "    ## Model\n",
        "    del auto_model\n",
        "    auto_model = BertGCN(hidden = 200,\n",
        "                vocabulary = train_data_helper.vocab,\n",
        "                n_grams = 5,\n",
        "                edges_mappings = edges_mappings,\n",
        "                edges_weights = edges_weights, \n",
        "                count = count, \n",
        "                num_classes = 2, \n",
        "                dropout_prob = 0.3\n",
        "                )\n",
        "\n",
        "\n",
        "    auto_model.to(device)\n",
        "\n",
        "    # Optimizer\n",
        "    num_total_steps = 1000\n",
        "    num_warmup_steps = 100\n",
        "    lr = 3e-6\n",
        "    param_optimizer = list(auto_model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "        'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n",
        "    \n",
        "    best_loss = None\n",
        "\n",
        "    auto_model.train()  \n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    n_epochs = 4\n",
        "\n",
        "    for epoch in (range(n_epochs)):  \n",
        "      # Training Loop\n",
        "      auto_model.train()\n",
        "      for step, batch in (enumerate(train_dataloader)):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_input_gcn ,b_len, b_labels = batch\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        outputs = auto_model(b_input_ids, \n",
        "                             b_input_mask, \n",
        "                             b_input_gcn, \n",
        "                             b_len, \n",
        "                             b_labels)\n",
        "\n",
        "        loss, logits = outputs[:2]\n",
        "        # print(loss)\n",
        "        # print(logits)\n",
        "        # sys.exit()\n",
        "\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "\n",
        "      # Validation Loop\n",
        "          \n",
        "      auto_model.eval()\n",
        "      eval_loss, eval_accuracy = 0, 0\n",
        "      nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "      yt, yp = [], []\n",
        "      for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_input_gcn ,b_len, b_labels = batch\n",
        "\n",
        "        with torch.no_grad():\n",
        "          outputs = auto_model(b_input_ids, \n",
        "                                attention_mask=b_input_mask,\n",
        "                                input_gcn = b_input_gcn,\n",
        "                                sent_len = b_len,\n",
        "                                labels= b_labels)        \n",
        "          loss, logits = outputs[:2]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        \n",
        "        preds = softmax(logits)\n",
        "        pred_ids = np.argmax(preds, axis=1).flatten()\n",
        "\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "\n",
        "        eval_loss += loss.item()\n",
        "        eval_accuracy += flat_accuracy(logits, label_ids)\n",
        "\n",
        "        yt = yt + label_ids.tolist()\n",
        "        yp = yp + pred_ids.tolist()\n",
        "\n",
        "        nb_eval_steps +=1\n",
        "        \n",
        "      print(\"Epoch {} | Train loss: {} | Validation Loss: {} \".format(epoch,\n",
        "                                                                      tr_loss/nb_tr_steps,\n",
        "                                                                      eval_loss/nb_eval_steps, \n",
        "                                                                    ))\n",
        "      if best_loss == None or best_loss > eval_loss/nb_eval_steps:\n",
        "        best_loss = eval_loss/nb_eval_steps\n",
        "        torch.save(auto_model.state_dict(), 'models/check_bertgcn.pth')\n",
        "        print(f'Saving model')\n",
        "      \n",
        "    \n",
        "    # test predictions\n",
        "    test_preds = []\n",
        "    auto_model.load_state_dict(torch.load('models/check_bertgcn.pth'))\n",
        "    auto_model.eval()\n",
        "    print('Loading best model')\n",
        "    \n",
        "    for batch in test_dataloader:\n",
        "      batch = tuple(t.to(device) for t in batch)\n",
        "      b_input_ids, b_input_mask, b_input_gcn ,b_len = batch\n",
        "\n",
        "      with torch.no_grad():\n",
        "        outputs = auto_model(b_input_ids, \n",
        "                              b_input_mask,\n",
        "                              b_input_gcn,\n",
        "                              b_len\n",
        "                            )        \n",
        "        logits = outputs[0]\n",
        "      logits = logits.detach().cpu().numpy()\n",
        "      preds = softmax(logits)[:, 1]        \n",
        "      test_preds = test_preds + preds.tolist()\n",
        "    \n",
        "    results[f'Fold_{f}'] = test_preds\n",
        "    \n",
        "\n",
        "\n",
        "    #if epoch == n_epochs:\n",
        "    print(classification_report(yt, yp))   \n",
        "    s = classification_report(yt, yp, output_dict=True)\n",
        "    S.append(s['1']['f1-score'])\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--------------------------------------------------------------------------------Fold # 0--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.4182675943681688 | Validation Loss: 0.2164306362469991 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.28425214130600746 | Validation Loss: 0.14387961328029633 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.21937864114803196 | Validation Loss: 0.14172490065296492 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.18122795619296306 | Validation Loss: 0.13333603392044704 \n",
            "Saving model\n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.96      0.97       280\n",
            "           1       0.94      0.97      0.96       188\n",
            "\n",
            "    accuracy                           0.96       468\n",
            "   macro avg       0.96      0.97      0.96       468\n",
            "weighted avg       0.96      0.96      0.96       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 1--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.4040436153158997 | Validation Loss: 0.13632706006368 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.2688138864257119 | Validation Loss: 0.06330533673365911 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.20584195815120834 | Validation Loss: 0.05395272026459376 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.16860198028999465 | Validation Loss: 0.0488531523073713 \n",
            "Saving model\n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      0.98      0.99       280\n",
            "           1       0.97      1.00      0.99       188\n",
            "\n",
            "    accuracy                           0.99       468\n",
            "   macro avg       0.99      0.99      0.99       468\n",
            "weighted avg       0.99      0.99      0.99       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 2--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.361070358674183 | Validation Loss: 0.14268939544757206 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.24003888761173142 | Validation Loss: 0.08448872442046801 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.18441506549998216 | Validation Loss: 0.0731421728928884 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.15088431314374742 | Validation Loss: 0.06640681649247805 \n",
            "Saving model\n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       281\n",
            "           1       0.96      0.99      0.98       187\n",
            "\n",
            "    accuracy                           0.98       468\n",
            "   macro avg       0.98      0.98      0.98       468\n",
            "weighted avg       0.98      0.98      0.98       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 3--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.31841629416202055 | Validation Loss: 0.16215768605470657 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.22235326198014346 | Validation Loss: 0.10775323112805685 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.17583170976734372 | Validation Loss: 0.0810971662402153 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.14568822318688035 | Validation Loss: 0.07360277399420738 \n",
            "Saving model\n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       281\n",
            "           1       0.97      0.98      0.97       187\n",
            "\n",
            "    accuracy                           0.98       468\n",
            "   macro avg       0.98      0.98      0.98       468\n",
            "weighted avg       0.98      0.98      0.98       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 4--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.367167755453424 | Validation Loss: 0.1588249330719312 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.24254690727331873 | Validation Loss: 0.12219197936356067 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.18761731768873605 | Validation Loss: 0.11309860597054164 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.15315163010646674 | Validation Loss: 0.12251399904489517 \n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       281\n",
            "           1       0.94      0.98      0.96       187\n",
            "\n",
            "    accuracy                           0.97       468\n",
            "   macro avg       0.96      0.97      0.97       468\n",
            "weighted avg       0.97      0.97      0.97       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 5--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.41822202255328494 | Validation Loss: 0.15051386281847953 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.2613008236089213 | Validation Loss: 0.12540862622360388 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.19632595434850741 | Validation Loss: 0.11773453305164973 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.1588863791725034 | Validation Loss: 0.11628496386110783 \n",
            "Saving model\n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       281\n",
            "           1       0.94      0.98      0.96       187\n",
            "\n",
            "    accuracy                           0.97       468\n",
            "   macro avg       0.96      0.97      0.97       468\n",
            "weighted avg       0.97      0.97      0.97       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 6--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.3974542258815332 | Validation Loss: 0.19199892779191335 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.2631842734038152 | Validation Loss: 0.1102959247926871 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.1995633171796046 | Validation Loss: 0.09780589193105697 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.161462686966512 | Validation Loss: 0.09702194916705291 \n",
            "Saving model\n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98       281\n",
            "           1       0.97      0.97      0.97       187\n",
            "\n",
            "    accuracy                           0.98       468\n",
            "   macro avg       0.98      0.98      0.98       468\n",
            "weighted avg       0.98      0.98      0.98       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 7--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.4636900414797393 | Validation Loss: 0.17509912550449372 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.29487781187124323 | Validation Loss: 0.08268297053873538 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.22154873060391783 | Validation Loss: 0.06846641140679519 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.179701146828434 | Validation Loss: 0.06774740119775137 \n",
            "Saving model\n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98       281\n",
            "           1       0.97      0.98      0.98       187\n",
            "\n",
            "    accuracy                           0.98       468\n",
            "   macro avg       0.98      0.98      0.98       468\n",
            "weighted avg       0.98      0.98      0.98       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 8--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.4507041080205729 | Validation Loss: 0.23342792789141337 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.29935970850232424 | Validation Loss: 0.11729166830579439 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.2265201804858416 | Validation Loss: 0.09458159034450848 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.18318340103812233 | Validation Loss: 0.09687701525787512 \n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.96      0.97       281\n",
            "           1       0.94      0.98      0.96       187\n",
            "\n",
            "    accuracy                           0.97       468\n",
            "   macro avg       0.97      0.97      0.97       468\n",
            "weighted avg       0.97      0.97      0.97       468\n",
            "\n",
            "--------------------------------------------------------------------------------Fold # 9--------------------------------------------------------------------\n",
            "135768\n",
            "torch.Size([135768, 1])\n",
            "Epoch 0 | Train loss: 0.3741953181046428 | Validation Loss: 0.16035986642042796 \n",
            "Saving model\n",
            "Epoch 1 | Train loss: 0.25353342083028774 | Validation Loss: 0.06026914070049922 \n",
            "Saving model\n",
            "Epoch 2 | Train loss: 0.19436061478718514 | Validation Loss: 0.050684927652279534 \n",
            "Saving model\n",
            "Epoch 3 | Train loss: 0.16039567492253176 | Validation Loss: 0.047531530261039734 \n",
            "Saving model\n",
            "Loading best model\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.99      0.99       280\n",
            "           1       0.99      0.97      0.98       187\n",
            "\n",
            "    accuracy                           0.99       467\n",
            "   macro avg       0.99      0.98      0.98       467\n",
            "weighted avg       0.99      0.99      0.98       467\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "layS6IlIQTtA",
        "colab_type": "code",
        "outputId": "ac3defcd-cb7d-442e-d938-621dc7ad8ea0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "S = np.array(S)\n",
        "S.mean()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.9704762728792533"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsnZdx2RQThZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp-fCsWLQTUb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZud6s5wQTGD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hESxtMgeKZvr",
        "colab_type": "code",
        "outputId": "6a4105c7-a702-4f1a-c458-2d31488aa38d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "results.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Fold_0</th>\n",
              "      <th>Fold_1</th>\n",
              "      <th>Fold_2</th>\n",
              "      <th>Fold_3</th>\n",
              "      <th>Fold_4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.473291</td>\n",
              "      <td>0.582156</td>\n",
              "      <td>0.773717</td>\n",
              "      <td>0.515028</td>\n",
              "      <td>0.552867</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.980621</td>\n",
              "      <td>0.788923</td>\n",
              "      <td>0.934692</td>\n",
              "      <td>0.872770</td>\n",
              "      <td>0.941588</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.576671</td>\n",
              "      <td>0.356888</td>\n",
              "      <td>0.449433</td>\n",
              "      <td>0.471735</td>\n",
              "      <td>0.473566</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.099559</td>\n",
              "      <td>0.111903</td>\n",
              "      <td>0.279063</td>\n",
              "      <td>0.209035</td>\n",
              "      <td>0.186653</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.988700</td>\n",
              "      <td>0.802909</td>\n",
              "      <td>0.962213</td>\n",
              "      <td>0.950028</td>\n",
              "      <td>0.977429</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Fold_0    Fold_1    Fold_2    Fold_3    Fold_4\n",
              "0  0.473291  0.582156  0.773717  0.515028  0.552867\n",
              "1  0.980621  0.788923  0.934692  0.872770  0.941588\n",
              "2  0.576671  0.356888  0.449433  0.471735  0.473566\n",
              "3  0.099559  0.111903  0.279063  0.209035  0.186653\n",
              "4  0.988700  0.802909  0.962213  0.950028  0.977429"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oOKLhL0iLiZM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results['Avg'] = 0\n",
        "for i in range(nfolds):\n",
        "  results['Avg'] += results[f'Fold_{i}']\n",
        "results['Avg'] /=nfolds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bdHXvKiZMidQ",
        "colab_type": "code",
        "outputId": "d40924ba-863e-48ae-beb2-b93a27195ea4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        }
      },
      "source": [
        "test_df['Logits'] = results['Avg']\n",
        "test_df['PredictedClass'] = (test_df['Logits']>=0.5)*1\n",
        "test_df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Subject</th>\n",
              "      <th>Sentence</th>\n",
              "      <th>Label\\n</th>\n",
              "      <th>Logits</th>\n",
              "      <th>PredictedClass</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>biology</td>\n",
              "      <td>Living things are highly organized and structu...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.579412</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>biology</td>\n",
              "      <td>The atom is the smallest and most fundamental ...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.903719</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>biology</td>\n",
              "      <td>It consists of a nucleus surrounded by electro...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.465659</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>biology</td>\n",
              "      <td>At its most fundamental level , life is made u...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.177243</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>biology</td>\n",
              "      <td>Matter is any substance that occupies space an...</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.936256</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Subject  ... PredictedClass\n",
              "0  biology  ...              1\n",
              "1  biology  ...              1\n",
              "2  biology  ...              0\n",
              "3  biology  ...              0\n",
              "4  biology  ...              1\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6FTw6UqzliW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_df.to_csv('sub/submission_hybrid_bert.csv', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "_N3pLdh6qr6L",
        "colab": {}
      },
      "source": [
        "# torch.save(auto_model.state_dict(), 'models/bert_attn_97_10fold.pth')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "G-KIjKKnqrBU",
        "colab": {}
      },
      "source": [
        "# auto_model.load_state_dict(torch.load('models/bert_attn_97_10fold.pth'))\n",
        "# print(f'Done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydXhiWSSumK9",
        "colab_type": "code",
        "outputId": "a667c3a1-d328-4f77-a209-78d8f7df42e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "test_df.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(859, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9HlRDbXsun_e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}