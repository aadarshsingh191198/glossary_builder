{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Bert_LM_final.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"7c4fb460855246498b31f0d85b5c56dc":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_d9516bdc7f16491a93694848fdd77cc6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_3781b1dcfbd249ce9c4164339fea2dba","IPY_MODEL_177dbe2239aa40b1bc23f01d38b8475d"]}},"d9516bdc7f16491a93694848fdd77cc6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"3781b1dcfbd249ce9c4164339fea2dba":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_23a098f0a4f843f0898aebb131a4de2a","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e8550d0e921a4a1392e84c066e9b3d18"}},"177dbe2239aa40b1bc23f01d38b8475d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_ecd3ae7ad1f04c21b50ccf36bf06370e","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 738kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_c32bbdc7b8f8434fbf33b9ced9fec6e0"}},"23a098f0a4f843f0898aebb131a4de2a":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e8550d0e921a4a1392e84c066e9b3d18":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"ecd3ae7ad1f04c21b50ccf36bf06370e":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"c32bbdc7b8f8434fbf33b9ced9fec6e0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7912d903764e47738a8c40b6d627e05d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_2d77e1582c6d4ddc8efe6fd20eb593a4","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_953a14af93c245359de08b6d6056305c","IPY_MODEL_2773f7b0a3634a9d944cbb1937359763"]}},"2d77e1582c6d4ddc8efe6fd20eb593a4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"953a14af93c245359de08b6d6056305c":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_3878abaf656b4ddca991a69a1f3d11d9","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":361,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":361,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_0df0476c170c43b3adacb4dd8aef910b"}},"2773f7b0a3634a9d944cbb1937359763":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_78910b4e36e14261886e60c48b428170","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 361/361 [59:47&lt;00:00, 9.94s/B]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_047678e5c2cd4149945f8b750ff47681"}},"3878abaf656b4ddca991a69a1f3d11d9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"0df0476c170c43b3adacb4dd8aef910b":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"78910b4e36e14261886e60c48b428170":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"047678e5c2cd4149945f8b750ff47681":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2655f0f2170448b1a3c03b6eaabd8894":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fb104b1dd9ae49b19711c61213547f0d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_8fd4da839a274caaa9df337f0c8d81b7","IPY_MODEL_6dc9002c544c458d95af163cda5ea29d"]}},"fb104b1dd9ae49b19711c61213547f0d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"8fd4da839a274caaa9df337f0c8d81b7":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_874ba20fb9df426ea2ec09bf369dff3e","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":435779157,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":435779157,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_4edc6966a8454825a6f631e534ea0e0f"}},"6dc9002c544c458d95af163cda5ea29d":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_4cc078960e1647c78131161a06f6d6e3","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 436M/436M [00:17&lt;00:00, 24.4MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_688e28babde74041acc7f4938291c6ce"}},"874ba20fb9df426ea2ec09bf369dff3e":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"4edc6966a8454825a6f631e534ea0e0f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"4cc078960e1647c78131161a06f6d6e3":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"688e28babde74041acc7f4938291c6ce":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"colab_type":"code","id":"z6TuFfcvZyno","outputId":"141732e0-2a71-4099-993c-a324160d0abf","executionInfo":{"status":"ok","timestamp":1585053863915,"user_tz":-330,"elapsed":26759,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LWFFLdrJZbNq","outputId":"32cfa597-82ea-4269-d0a0-2e9e4ccc9904","executionInfo":{"status":"ok","timestamp":1585053883882,"user_tz":-330,"elapsed":8811,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":104}},"source":["! pip install transformers -q"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 501kB 10.0MB/s \n","\u001b[K     |████████████████████████████████| 3.7MB 54.3MB/s \n","\u001b[K     |████████████████████████████████| 870kB 61.4MB/s \n","\u001b[K     |████████████████████████████████| 1.0MB 57.8MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9W8iuy5iZbN0","colab":{}},"source":["import csv\n","import re\n","import pandas as pd\n","from pathlib import Path\n","import matplotlib.cm as cm\n","from fastai import *\n","from fastai.text import *\n","from fastai.callbacks import *\n","from fastai.metrics import *\n","import numpy as np\n","import pandas as pd\n","\n","from pathlib import Path\n","from typing import *\n","\n","from tqdm import tqdm\n","import torch\n","import torch.optim as optim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WJUOCfwJ7nG7","colab":{}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bDcJAbWQmWmW","colab":{}},"source":["seed = 42\n","\n","# python RNG\n","import random\n","random.seed(seed)\n","\n","# pytorch RNGs\n","import torch\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","\n","# numpy RNG\n","import numpy as np\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pfkl3wOmaRkt","outputId":"9001370a-594c-4e23-94c7-124b1e4860f7","executionInfo":{"status":"ok","timestamp":1585053919751,"user_tz":-330,"elapsed":10729,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":295}},"source":["import os\n","os.chdir('/gdrive/My Drive/DEFINITION EXTRACTION/DEFT_Updated')\n","! ls"],"execution_count":6,"outputs":[{"output_type":"stream","text":["BERT_attention_kfold.ipynb\t   rbert_ft\n","bert_cached_lm_510_deft.test.raw   roberta_cached_lm_510_deft.test.raw\n","bert_cached_lm_510_deft.train.raw  roberta_cached_lm_510_deft.train.raw\n","bert_ft\t\t\t\t   RobertaLM_GB_kfold.ipynb\n","catboost_info\t\t\t   roberta_tuned_test.npy\n","deft.test.raw\t\t\t   roberta_tuned_train.npy\n","deft.train.raw\t\t\t   runs\n","DualXLNet_attention_kfold.ipynb    sub\n","GCN_BERT_attention_kfold.ipynb\t   task1_dev.csv\n","GCN_BERT_dependency_kfold.ipynb    task1_test.csv\n","GCN_BERT_final.ipynb\t\t   task1_train.csv\n","gcn_dep.ipynb\t\t\t   train_lm.py\n","gcn.ipynb\t\t\t   vocab.txt\n","gcn_model.pkl\t\t\t   WCL_cased_symbols.csv\n","glove.6B.200d.vec.txt\t\t   XLNET_attention_kfold.ipynb\n","models\t\t\t\t   XLNET_GCN_attention_kfold.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"17X4qG7RZbN-","colab":{}},"source":["# model_name=\"bert-base-cased\"\n","# model_name=\"roberta-base\"\n","# model_name=\"xlnet-base-cased\"\n","# model_name = 'distilbert-base-cased'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHkuwclg5EFy","colab_type":"code","colab":{}},"source":["TEXT_COL = 'Sentence'\n","Y_COL = 'Label'\n","PTEXT_COL = 'SSentence'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxp-rwB2jm4_","colab_type":"code","colab":{}},"source":["import re\n","def multi_replace(chars_to_replace, char_to_place, from_string):\n","    for char in chars_to_replace:\n","        from_string = from_string.replace(char,char_to_place)\n","    return from_string\n","\n","def preprocessing(sentence):\n","    remove_punct = multi_replace(',“”’.-{}[]()=+_!@#$%^&*<>?/|\\\\~`:;\"','',sentence)\n","    return remove_punct\n","\n","def load_data(file):\n","    df = pd.read_csv(file)\n","    # removing initial numbers\n","    df[TEXT_COL] = df[TEXT_COL].apply(lambda x : re.findall('^\\s*\\d*\\s*\\.?\\s*(.*)',x)[0])\n","    # preprocessing\n","    # df[TEXT_COL] = df[TEXT_COL].apply(preprocessing)\n","    return df\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9Ad9AScmzi00","outputId":"ac170590-8e73-42e2-fbb9-3e0d484b1419","executionInfo":{"status":"ok","timestamp":1585053920500,"user_tz":-330,"elapsed":9824,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":112}},"source":["train_df = load_data('task1_train.csv')\n","train_df.head(2)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>biology</td>\n","      <td>Science includes such diverse fields as astron...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>biology</td>\n","      <td>However , those fields of science related to t...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Subject                                           Sentence  Label\n","0  biology  Science includes such diverse fields as astron...      0\n","1  biology  However , those fields of science related to t...      1"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"EfRriLZ41WDb","colab_type":"code","outputId":"381ab582-4b3b-4755-f823-811442cb62e6","executionInfo":{"status":"ok","timestamp":1585053921010,"user_tz":-330,"elapsed":9708,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":112}},"source":["dev_df = load_data('task1_dev.csv')\n","dev_df.head(2)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>biology</td>\n","      <td>It becomes clear from this definition that the...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>biology</td>\n","      <td>The scientific method is a method of research ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Subject                                           Sentence  Label\n","0  biology  It becomes clear from this definition that the...      0\n","1  biology  The scientific method is a method of research ...      1"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Rn97INefxSRk","colab_type":"code","outputId":"da4107ee-f94d-45b7-dd97-134584c54d16","executionInfo":{"status":"ok","timestamp":1585053921564,"user_tz":-330,"elapsed":9560,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":112}},"source":["test_df = load_data('task1_test.csv')\n","test_df.head(2)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label\\n</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>biology</td>\n","      <td>Living things are highly organized and structu...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>biology</td>\n","      <td>The atom is the smallest and most fundamental ...</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Subject                                           Sentence  Label\\n\n","0  biology  Living things are highly organized and structu...      NaN\n","1  biology  The atom is the smallest and most fundamental ...      NaN"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"btD2sXqA2-D_","colab_type":"code","outputId":"7b655e46-68b6-4b68-8cc4-44a60aa4430c","executionInfo":{"status":"ok","timestamp":1585053921566,"user_tz":-330,"elapsed":8835,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["def subj(row):\n","  return '< ' + row['Subject'] + ' > ' + row[TEXT_COL] \n","\n","train_df[PTEXT_COL] = train_df.apply(subj, axis=1)\n","dev_df[PTEXT_COL] = dev_df.apply(subj, axis=1)\n","test_df[PTEXT_COL] = test_df.apply(subj, axis=1)\n","\n","train_df.head()"],"execution_count":13,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","      <th>SSentence</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>biology</td>\n","      <td>Science includes such diverse fields as astron...</td>\n","      <td>0</td>\n","      <td>&lt; biology &gt; Science includes such diverse fiel...</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>biology</td>\n","      <td>However , those fields of science related to t...</td>\n","      <td>1</td>\n","      <td>&lt; biology &gt; However , those fields of science ...</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>biology</td>\n","      <td>Thus , a museum of natural sciences might cont...</td>\n","      <td>0</td>\n","      <td>&lt; biology &gt; Thus , a museum of natural science...</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>biology</td>\n","      <td>In deductive reason , the pattern of thinking ...</td>\n","      <td>0</td>\n","      <td>&lt; biology &gt; In deductive reason , the pattern ...</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>biology</td>\n","      <td>Deductive reasoning is a form of logical think...</td>\n","      <td>1</td>\n","      <td>&lt; biology &gt; Deductive reasoning is a form of l...</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Subject  ...                                          SSentence\n","0  biology  ...  < biology > Science includes such diverse fiel...\n","1  biology  ...  < biology > However , those fields of science ...\n","2  biology  ...  < biology > Thus , a museum of natural science...\n","3  biology  ...  < biology > In deductive reason , the pattern ...\n","4  biology  ...  < biology > Deductive reasoning is a form of l...\n","\n","[5 rows x 4 columns]"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"GxxHtFT_4VQg","colab_type":"code","outputId":"13a33897-75c8-4eab-f679-790a765af760","executionInfo":{"status":"ok","timestamp":1585053921569,"user_tz":-330,"elapsed":8269,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["merged = pd.concat([train_df, dev_df])\n","merged.shape"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(18315, 4)"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"SJJSF9ukTFKX"},"source":["## Transformer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8TBbnX8TZbOF","colab":{}},"source":[" %tensorflow_version 1.x \n","from transformers import *"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WNqR52EuqAzl","colab_type":"text"},"source":["## Language Model"]},{"cell_type":"code","metadata":{"id":"yp81X26KpOea","colab_type":"code","colab":{}},"source":["# from tqdm import tqdm\n","# with open('deft.train.raw', 'w') as f:\n","#   for i,row in tqdm(merged.iterrows()):\n","#     f.write(row[TEXT_COL])\n","\n","# with open('deft.test.raw', 'w') as f:\n","#   for i,row in tqdm(test_df.iterrows()):\n","#     f.write(row[TEXT_COL])\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OaadsF12qCdf","colab_type":"code","outputId":"d697d14c-b7d9-4cce-d49d-e27aefd5c808","executionInfo":{"status":"ok","timestamp":1585030796687,"user_tz":-330,"elapsed":135793,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":1000}},"source":["! rm -rf bert_ft\n","! mkdir bert_ft\n","! python train_lm.py \\\n","    --output_dir=bert_ft \\\n","    --model_type=bert \\\n","    --model_name_or_path=bert-base-cased \\\n","    --do_train \\\n","    --train_data_file=./deft.train.raw \\\n","    --do_eval \\\n","    --eval_data_file=./deft.test.raw \\\n","    --mlm\\"],"execution_count":0,"outputs":[{"output_type":"stream","text":["03/24/2020 06:17:59 - WARNING - __main__ -   Process rank: -1, device: cuda, n_gpu: 1, distributed training: False, 16-bits training: False\n","03/24/2020 06:18:00 - INFO - filelock -   Lock 140537224312648 acquired on /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e.lock\n","03/24/2020 06:18:00 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp__cnau_g\n","Downloading: 100% 361/361 [00:00<00:00, 293kB/s]\n","03/24/2020 06:18:00 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json in cache at /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e\n","03/24/2020 06:18:00 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e\n","03/24/2020 06:18:00 - INFO - filelock -   Lock 140537224312648 released on /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e.lock\n","03/24/2020 06:18:00 - INFO - transformers.configuration_utils -   loading configuration file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-config.json from cache at /root/.cache/torch/transformers/b945b69218e98b3e2c95acf911789741307dec43c698d35fad11c1ae28bda352.3d5adf10d3445c36ce131f4c6416aa62e9b58e1af56b97664773f4858a46286e\n","03/24/2020 06:18:00 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": null,\n","  \"do_sample\": false,\n","  \"eos_token_ids\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 28996\n","}\n","\n","03/24/2020 06:18:00 - INFO - filelock -   Lock 140536851468808 acquired on /root/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1.lock\n","03/24/2020 06:18:00 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmp8jdk2j39\n","Downloading: 100% 213k/213k [00:00<00:00, 1.12MB/s]\n","03/24/2020 06:18:01 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt in cache at /root/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","03/24/2020 06:18:01 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","03/24/2020 06:18:01 - INFO - filelock -   Lock 140536851468808 released on /root/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1.lock\n","03/24/2020 06:18:01 - INFO - transformers.tokenization_utils -   loading file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-vocab.txt from cache at /root/.cache/torch/transformers/5e8a2b4893d13790ed4150ca1906be5f7a03d6c4ddf62296c383f6db42814db2.e13dbb970cb325137104fb2e5f36fe865f27746c6b526f6352861b1980eb80b1\n","03/24/2020 06:18:01 - INFO - filelock -   Lock 140536851472112 acquired on /root/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2.lock\n","03/24/2020 06:18:01 - INFO - transformers.file_utils -   https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin not found in cache or force_download set to True, downloading to /root/.cache/torch/transformers/tmppw110o5a\n","Downloading: 100% 436M/436M [00:11<00:00, 38.0MB/s]\n","03/24/2020 06:18:13 - INFO - transformers.file_utils -   storing https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin in cache at /root/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n","03/24/2020 06:18:13 - INFO - transformers.file_utils -   creating metadata file for /root/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n","03/24/2020 06:18:13 - INFO - filelock -   Lock 140536851472112 released on /root/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2.lock\n","03/24/2020 06:18:13 - INFO - transformers.modeling_utils -   loading weights file https://s3.amazonaws.com/models.huggingface.co/bert/bert-base-cased-pytorch_model.bin from cache at /root/.cache/torch/transformers/35d8b9d36faaf46728a0192d82bf7d00137490cd6074e8500778afed552a67e5.3fadbea36527ae472139fe84cddaa65454d7429f12d543d80bfc3ad70de55ac2\n","03/24/2020 06:18:16 - INFO - transformers.modeling_utils -   Weights of BertForMaskedLM not initialized from pretrained model: ['cls.predictions.decoder.bias']\n","03/24/2020 06:18:16 - INFO - transformers.modeling_utils -   Weights from pretrained model not used in BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n","03/24/2020 06:18:26 - INFO - __main__ -   Training/evaluation parameters Namespace(adam_epsilon=1e-08, block_size=512, cache_dir=None, config_name=None, device=device(type='cuda'), do_eval=True, do_train=True, eval_all_checkpoints=False, eval_data_file='./deft.test.raw', evaluate_during_training=False, fp16=False, fp16_opt_level='O1', gradient_accumulation_steps=1, learning_rate=5e-05, line_by_line=False, local_rank=-1, logging_steps=500, max_grad_norm=1.0, max_steps=-1, mlm=True, mlm_probability=0.15, model_name_or_path='bert-base-cased', model_type='bert', n_gpu=1, no_cuda=False, num_train_epochs=1.0, output_dir='bert_ft', overwrite_cache=False, overwrite_output_dir=False, per_gpu_eval_batch_size=4, per_gpu_train_batch_size=4, save_steps=500, save_total_limit=None, seed=42, server_ip='', server_port='', should_continue=False, tokenizer_name=None, train_data_file='./deft.train.raw', warmup_steps=0, weight_decay=0.0)\n","03/24/2020 06:18:26 - INFO - __main__ -   Loading features from cached file ./bert_cached_lm_510_deft.train.raw\n","03/24/2020 06:18:26 - INFO - __main__ -   ***** Running training *****\n","03/24/2020 06:18:26 - INFO - __main__ -     Num examples = 1047\n","03/24/2020 06:18:26 - INFO - __main__ -     Num Epochs = 1\n","03/24/2020 06:18:26 - INFO - __main__ -     Instantaneous batch size per GPU = 4\n","03/24/2020 06:18:26 - INFO - __main__ -     Total train batch size (w. parallel, distributed & accumulation) = 4\n","03/24/2020 06:18:26 - INFO - __main__ -     Gradient Accumulation steps = 1\n","03/24/2020 06:18:26 - INFO - __main__ -     Total optimization steps = 262\n","Epoch:   0% 0/1 [00:00<?, ?it/s]\n","Iteration:   0% 0/262 [00:00<?, ?it/s]\u001b[A\n","Iteration:   0% 1/262 [00:00<02:45,  1.58it/s]\u001b[A\n","Iteration:   1% 2/262 [00:00<02:18,  1.87it/s]\u001b[A\n","Iteration:   1% 3/262 [00:01<01:59,  2.16it/s]\u001b[A\n","Iteration:   2% 4/262 [00:01<01:46,  2.42it/s]\u001b[A\n","Iteration:   2% 5/262 [00:01<01:37,  2.64it/s]\u001b[A\n","Iteration:   2% 6/262 [00:02<01:30,  2.83it/s]\u001b[A\n","Iteration:   3% 7/262 [00:02<01:25,  2.97it/s]\u001b[A\n","Iteration:   3% 8/262 [00:02<01:22,  3.09it/s]\u001b[A\n","Iteration:   3% 9/262 [00:03<01:20,  3.15it/s]\u001b[A\n","Iteration:   4% 10/262 [00:03<01:18,  3.21it/s]\u001b[A\n","Iteration:   4% 11/262 [00:03<01:16,  3.26it/s]\u001b[A\n","Iteration:   5% 12/262 [00:03<01:15,  3.30it/s]\u001b[A\n","Iteration:   5% 13/262 [00:04<01:15,  3.31it/s]\u001b[A\n","Iteration:   5% 14/262 [00:04<01:14,  3.34it/s]\u001b[A\n","Iteration:   6% 15/262 [00:04<01:13,  3.35it/s]\u001b[A\n","Iteration:   6% 16/262 [00:05<01:13,  3.35it/s]\u001b[A\n","Iteration:   6% 17/262 [00:05<01:13,  3.35it/s]\u001b[A\n","Iteration:   7% 18/262 [00:05<01:12,  3.35it/s]\u001b[A\n","Iteration:   7% 19/262 [00:05<01:12,  3.35it/s]\u001b[A\n","Iteration:   8% 20/262 [00:06<01:12,  3.35it/s]\u001b[A\n","Iteration:   8% 21/262 [00:06<01:12,  3.34it/s]\u001b[A\n","Iteration:   8% 22/262 [00:06<01:11,  3.35it/s]\u001b[A\n","Iteration:   9% 23/262 [00:07<01:11,  3.35it/s]\u001b[A\n","Iteration:   9% 24/262 [00:07<01:11,  3.35it/s]\u001b[A\n","Iteration:  10% 25/262 [00:07<01:10,  3.36it/s]\u001b[A\n","Iteration:  10% 26/262 [00:08<01:10,  3.37it/s]\u001b[A\n","Iteration:  10% 27/262 [00:08<01:09,  3.36it/s]\u001b[A\n","Iteration:  11% 28/262 [00:08<01:09,  3.37it/s]\u001b[A\n","Iteration:  11% 29/262 [00:08<01:08,  3.38it/s]\u001b[A\n","Iteration:  11% 30/262 [00:09<01:08,  3.39it/s]\u001b[A\n","Iteration:  12% 31/262 [00:09<01:08,  3.39it/s]\u001b[A\n","Iteration:  12% 32/262 [00:09<01:07,  3.40it/s]\u001b[A\n","Iteration:  13% 33/262 [00:10<01:07,  3.40it/s]\u001b[A\n","Iteration:  13% 34/262 [00:10<01:07,  3.39it/s]\u001b[A\n","Iteration:  13% 35/262 [00:10<01:07,  3.39it/s]\u001b[A\n","Iteration:  14% 36/262 [00:11<01:06,  3.38it/s]\u001b[A\n","Iteration:  14% 37/262 [00:11<01:06,  3.37it/s]\u001b[A\n","Iteration:  15% 38/262 [00:11<01:06,  3.37it/s]\u001b[A\n","Iteration:  15% 39/262 [00:11<01:06,  3.36it/s]\u001b[A\n","Iteration:  15% 40/262 [00:12<01:06,  3.34it/s]\u001b[A\n","Iteration:  16% 41/262 [00:12<01:05,  3.36it/s]\u001b[A\n","Iteration:  16% 42/262 [00:12<01:05,  3.36it/s]\u001b[A\n","Iteration:  16% 43/262 [00:13<01:05,  3.36it/s]\u001b[A\n","Iteration:  17% 44/262 [00:13<01:04,  3.37it/s]\u001b[A\n","Iteration:  17% 45/262 [00:13<01:04,  3.38it/s]\u001b[A\n","Iteration:  18% 46/262 [00:13<01:03,  3.39it/s]\u001b[A\n","Iteration:  18% 47/262 [00:14<01:03,  3.38it/s]\u001b[A\n","Iteration:  18% 48/262 [00:14<01:03,  3.39it/s]\u001b[A\n","Iteration:  19% 49/262 [00:14<01:02,  3.38it/s]\u001b[A\n","Iteration:  19% 50/262 [00:15<01:02,  3.37it/s]\u001b[A\n","Iteration:  19% 51/262 [00:15<01:02,  3.37it/s]\u001b[A\n","Iteration:  20% 52/262 [00:15<01:02,  3.34it/s]\u001b[A\n","Iteration:  20% 53/262 [00:16<01:02,  3.35it/s]\u001b[A\n","Iteration:  21% 54/262 [00:16<01:02,  3.35it/s]\u001b[A\n","Iteration:  21% 55/262 [00:16<01:01,  3.36it/s]\u001b[A\n","Iteration:  21% 56/262 [00:16<01:01,  3.36it/s]\u001b[A\n","Iteration:  22% 57/262 [00:17<01:00,  3.37it/s]\u001b[A\n","Iteration:  22% 58/262 [00:17<01:00,  3.37it/s]\u001b[A\n","Iteration:  23% 59/262 [00:17<01:00,  3.38it/s]\u001b[A\n","Iteration:  23% 60/262 [00:18<00:59,  3.39it/s]\u001b[A\n","Iteration:  23% 61/262 [00:18<00:59,  3.39it/s]\u001b[A\n","Iteration:  24% 62/262 [00:18<00:58,  3.40it/s]\u001b[A\n","Iteration:  24% 63/262 [00:19<00:58,  3.40it/s]\u001b[A\n","Iteration:  24% 64/262 [00:19<00:58,  3.40it/s]\u001b[A\n","Iteration:  25% 65/262 [00:19<00:58,  3.39it/s]\u001b[A\n","Iteration:  25% 66/262 [00:19<00:57,  3.38it/s]\u001b[A\n","Iteration:  26% 67/262 [00:20<00:57,  3.38it/s]\u001b[A\n","Iteration:  26% 68/262 [00:20<00:57,  3.38it/s]\u001b[A\n","Iteration:  26% 69/262 [00:20<00:57,  3.37it/s]\u001b[A\n","Iteration:  27% 70/262 [00:21<00:57,  3.37it/s]\u001b[A\n","Iteration:  27% 71/262 [00:21<00:57,  3.35it/s]\u001b[A\n","Iteration:  27% 72/262 [00:21<00:56,  3.37it/s]\u001b[A\n","Iteration:  28% 73/262 [00:21<00:56,  3.37it/s]\u001b[A\n","Iteration:  28% 74/262 [00:22<00:55,  3.37it/s]\u001b[A\n","Iteration:  29% 75/262 [00:22<00:55,  3.38it/s]\u001b[A\n","Iteration:  29% 76/262 [00:22<00:54,  3.39it/s]\u001b[A\n","Iteration:  29% 77/262 [00:23<00:54,  3.39it/s]\u001b[A\n","Iteration:  30% 78/262 [00:23<00:54,  3.36it/s]\u001b[A\n","Iteration:  30% 79/262 [00:23<00:54,  3.37it/s]\u001b[A\n","Iteration:  31% 80/262 [00:24<00:53,  3.37it/s]\u001b[A\n","Iteration:  31% 81/262 [00:24<00:53,  3.37it/s]\u001b[A\n","Iteration:  31% 82/262 [00:24<00:53,  3.36it/s]\u001b[A\n","Iteration:  32% 83/262 [00:24<00:53,  3.36it/s]\u001b[A\n","Iteration:  32% 84/262 [00:25<00:53,  3.35it/s]\u001b[A\n","Iteration:  32% 85/262 [00:25<00:52,  3.35it/s]\u001b[A\n","Iteration:  33% 86/262 [00:25<00:52,  3.36it/s]\u001b[A\n","Iteration:  33% 87/262 [00:26<00:52,  3.36it/s]\u001b[A\n","Iteration:  34% 88/262 [00:26<00:51,  3.37it/s]\u001b[A\n","Iteration:  34% 89/262 [00:26<00:51,  3.36it/s]\u001b[A\n","Iteration:  34% 90/262 [00:27<00:50,  3.37it/s]\u001b[A\n","Iteration:  35% 91/262 [00:27<00:50,  3.38it/s]\u001b[A\n","Iteration:  35% 92/262 [00:27<00:50,  3.39it/s]\u001b[A\n","Iteration:  35% 93/262 [00:27<00:49,  3.40it/s]\u001b[A\n","Iteration:  36% 94/262 [00:28<00:49,  3.40it/s]\u001b[A\n","Iteration:  36% 95/262 [00:28<00:49,  3.39it/s]\u001b[A\n","Iteration:  37% 96/262 [00:28<00:49,  3.37it/s]\u001b[A\n","Iteration:  37% 97/262 [00:29<00:48,  3.37it/s]\u001b[A\n","Iteration:  37% 98/262 [00:29<00:48,  3.37it/s]\u001b[A\n","Iteration:  38% 99/262 [00:29<00:48,  3.37it/s]\u001b[A\n","Iteration:  38% 100/262 [00:30<00:48,  3.36it/s]\u001b[A\n","Iteration:  39% 101/262 [00:30<00:47,  3.37it/s]\u001b[A\n","Iteration:  39% 102/262 [00:30<00:47,  3.38it/s]\u001b[A\n","Iteration:  39% 103/262 [00:30<00:47,  3.38it/s]\u001b[A\n","Iteration:  40% 104/262 [00:31<00:46,  3.39it/s]\u001b[A\n","Iteration:  40% 105/262 [00:31<00:46,  3.39it/s]\u001b[A\n","Iteration:  40% 106/262 [00:31<00:45,  3.40it/s]\u001b[A\n","Iteration:  41% 107/262 [00:32<00:45,  3.39it/s]\u001b[A\n","Iteration:  41% 108/262 [00:32<00:45,  3.39it/s]\u001b[A\n","Iteration:  42% 109/262 [00:32<00:45,  3.39it/s]\u001b[A\n","Iteration:  42% 110/262 [00:32<00:44,  3.38it/s]\u001b[A\n","Iteration:  42% 111/262 [00:33<00:44,  3.37it/s]\u001b[A\n","Iteration:  43% 112/262 [00:33<00:44,  3.37it/s]\u001b[A\n","Iteration:  43% 113/262 [00:33<00:44,  3.37it/s]\u001b[A\n","Iteration:  44% 114/262 [00:34<00:43,  3.37it/s]\u001b[A\n","Iteration:  44% 115/262 [00:34<00:43,  3.37it/s]\u001b[A\n","Iteration:  44% 116/262 [00:34<00:43,  3.36it/s]\u001b[A\n","Iteration:  45% 117/262 [00:35<00:43,  3.37it/s]\u001b[A\n","Iteration:  45% 118/262 [00:35<00:42,  3.37it/s]\u001b[A\n","Iteration:  45% 119/262 [00:35<00:42,  3.37it/s]\u001b[A\n","Iteration:  46% 120/262 [00:35<00:41,  3.39it/s]\u001b[A\n","Iteration:  46% 121/262 [00:36<00:41,  3.39it/s]\u001b[A\n","Iteration:  47% 122/262 [00:36<00:41,  3.39it/s]\u001b[A\n","Iteration:  47% 123/262 [00:36<00:40,  3.40it/s]\u001b[A\n","Iteration:  47% 124/262 [00:37<00:40,  3.39it/s]\u001b[A\n","Iteration:  48% 125/262 [00:37<00:40,  3.39it/s]\u001b[A\n","Iteration:  48% 126/262 [00:37<00:40,  3.36it/s]\u001b[A\n","Iteration:  48% 127/262 [00:37<00:40,  3.36it/s]\u001b[A\n","Iteration:  49% 128/262 [00:38<00:39,  3.37it/s]\u001b[A\n","Iteration:  49% 129/262 [00:38<00:39,  3.36it/s]\u001b[A\n","Iteration:  50% 130/262 [00:38<00:39,  3.36it/s]\u001b[A\n","Iteration:  50% 131/262 [00:39<00:39,  3.35it/s]\u001b[A\n","Iteration:  50% 132/262 [00:39<00:38,  3.37it/s]\u001b[A\n","Iteration:  51% 133/262 [00:39<00:38,  3.36it/s]\u001b[A\n","Iteration:  51% 134/262 [00:40<00:37,  3.37it/s]\u001b[A\n","Iteration:  52% 135/262 [00:40<00:37,  3.36it/s]\u001b[A\n","Iteration:  52% 136/262 [00:40<00:37,  3.36it/s]\u001b[A\n","Iteration:  52% 137/262 [00:40<00:37,  3.37it/s]\u001b[A\n","Iteration:  53% 138/262 [00:41<00:36,  3.35it/s]\u001b[A\n","Iteration:  53% 139/262 [00:41<00:36,  3.36it/s]\u001b[A\n","Iteration:  53% 140/262 [00:41<00:36,  3.37it/s]\u001b[A\n","Iteration:  54% 141/262 [00:42<00:35,  3.37it/s]\u001b[A\n","Iteration:  54% 142/262 [00:42<00:35,  3.37it/s]\u001b[A\n","Iteration:  55% 143/262 [00:42<00:35,  3.37it/s]\u001b[A\n","Iteration:  55% 144/262 [00:43<00:35,  3.36it/s]\u001b[A\n","Iteration:  55% 145/262 [00:43<00:34,  3.36it/s]\u001b[A\n","Iteration:  56% 146/262 [00:43<00:34,  3.36it/s]\u001b[A\n","Iteration:  56% 147/262 [00:43<00:34,  3.37it/s]\u001b[A\n","Iteration:  56% 148/262 [00:44<00:33,  3.37it/s]\u001b[A\n","Iteration:  57% 149/262 [00:44<00:33,  3.36it/s]\u001b[A\n","Iteration:  57% 150/262 [00:44<00:33,  3.35it/s]\u001b[A\n","Iteration:  58% 151/262 [00:45<00:33,  3.36it/s]\u001b[A\n","Iteration:  58% 152/262 [00:45<00:32,  3.38it/s]\u001b[A\n","Iteration:  58% 153/262 [00:45<00:32,  3.39it/s]\u001b[A\n","Iteration:  59% 154/262 [00:46<00:31,  3.39it/s]\u001b[A\n","Iteration:  59% 155/262 [00:46<00:31,  3.39it/s]\u001b[A\n","Iteration:  60% 156/262 [00:46<00:31,  3.39it/s]\u001b[A\n","Iteration:  60% 157/262 [00:46<00:31,  3.37it/s]\u001b[A\n","Iteration:  60% 158/262 [00:47<00:30,  3.37it/s]\u001b[A\n","Iteration:  61% 159/262 [00:47<00:30,  3.37it/s]\u001b[A\n","Iteration:  61% 160/262 [00:47<00:30,  3.37it/s]\u001b[A\n","Iteration:  61% 161/262 [00:48<00:29,  3.37it/s]\u001b[A\n","Iteration:  62% 162/262 [00:48<00:29,  3.37it/s]\u001b[A\n","Iteration:  62% 163/262 [00:48<00:29,  3.35it/s]\u001b[A\n","Iteration:  63% 164/262 [00:48<00:29,  3.36it/s]\u001b[A\n","Iteration:  63% 165/262 [00:49<00:28,  3.38it/s]\u001b[A\n","Iteration:  63% 166/262 [00:49<00:28,  3.39it/s]\u001b[A\n","Iteration:  64% 167/262 [00:49<00:27,  3.39it/s]\u001b[A\n","Iteration:  64% 168/262 [00:50<00:27,  3.40it/s]\u001b[A\n","Iteration:  65% 169/262 [00:50<00:27,  3.40it/s]\u001b[A\n","Iteration:  65% 170/262 [00:50<00:27,  3.40it/s]\u001b[A\n","Iteration:  65% 171/262 [00:51<00:26,  3.39it/s]\u001b[A\n","Iteration:  66% 172/262 [00:51<00:26,  3.38it/s]\u001b[A\n","Iteration:  66% 173/262 [00:51<00:26,  3.38it/s]\u001b[A\n","Iteration:  66% 174/262 [00:51<00:26,  3.37it/s]\u001b[A\n","Iteration:  67% 175/262 [00:52<00:25,  3.38it/s]\u001b[A\n","Iteration:  67% 176/262 [00:52<00:25,  3.39it/s]\u001b[A\n","Iteration:  68% 177/262 [00:52<00:25,  3.39it/s]\u001b[A\n","Iteration:  68% 178/262 [00:53<00:24,  3.39it/s]\u001b[A\n","Iteration:  68% 179/262 [00:53<00:24,  3.40it/s]\u001b[A\n","Iteration:  69% 180/262 [00:53<00:24,  3.40it/s]\u001b[A\n","Iteration:  69% 181/262 [00:53<00:23,  3.40it/s]\u001b[A\n","Iteration:  69% 182/262 [00:54<00:23,  3.41it/s]\u001b[A\n","Iteration:  70% 183/262 [00:54<00:23,  3.39it/s]\u001b[A\n","Iteration:  70% 184/262 [00:54<00:23,  3.38it/s]\u001b[A\n","Iteration:  71% 185/262 [00:55<00:22,  3.38it/s]\u001b[A\n","Iteration:  71% 186/262 [00:55<00:22,  3.37it/s]\u001b[A\n","Iteration:  71% 187/262 [00:55<00:22,  3.37it/s]\u001b[A\n","Iteration:  72% 188/262 [00:56<00:22,  3.35it/s]\u001b[A\n","Iteration:  72% 189/262 [00:56<00:21,  3.35it/s]\u001b[A\n","Iteration:  73% 190/262 [00:56<00:21,  3.36it/s]\u001b[A\n","Iteration:  73% 191/262 [00:56<00:21,  3.37it/s]\u001b[A\n","Iteration:  73% 192/262 [00:57<00:20,  3.37it/s]\u001b[A\n","Iteration:  74% 193/262 [00:57<00:20,  3.38it/s]\u001b[A\n","Iteration:  74% 194/262 [00:57<00:20,  3.38it/s]\u001b[A\n","Iteration:  74% 195/262 [00:58<00:19,  3.39it/s]\u001b[A\n","Iteration:  75% 196/262 [00:58<00:19,  3.40it/s]\u001b[A\n","Iteration:  75% 197/262 [00:58<00:19,  3.40it/s]\u001b[A\n","Iteration:  76% 198/262 [00:59<00:18,  3.40it/s]\u001b[A\n","Iteration:  76% 199/262 [00:59<00:18,  3.39it/s]\u001b[A\n","Iteration:  76% 200/262 [00:59<00:18,  3.39it/s]\u001b[A\n","Iteration:  77% 201/262 [00:59<00:18,  3.39it/s]\u001b[A\n","Iteration:  77% 202/262 [01:00<00:17,  3.39it/s]\u001b[A\n","Iteration:  77% 203/262 [01:00<00:17,  3.38it/s]\u001b[A\n","Iteration:  78% 204/262 [01:00<00:17,  3.37it/s]\u001b[A\n","Iteration:  78% 205/262 [01:01<00:16,  3.38it/s]\u001b[A\n","Iteration:  79% 206/262 [01:01<00:16,  3.38it/s]\u001b[A\n","Iteration:  79% 207/262 [01:01<00:16,  3.39it/s]\u001b[A\n","Iteration:  79% 208/262 [01:01<00:15,  3.39it/s]\u001b[A\n","Iteration:  80% 209/262 [01:02<00:15,  3.39it/s]\u001b[A\n","Iteration:  80% 210/262 [01:02<00:15,  3.40it/s]\u001b[A\n","Iteration:  81% 211/262 [01:02<00:14,  3.40it/s]\u001b[A\n","Iteration:  81% 212/262 [01:03<00:14,  3.39it/s]\u001b[A\n","Iteration:  81% 213/262 [01:03<00:14,  3.39it/s]\u001b[A\n","Iteration:  82% 214/262 [01:03<00:14,  3.38it/s]\u001b[A\n","Iteration:  82% 215/262 [01:04<00:13,  3.38it/s]\u001b[A\n","Iteration:  82% 216/262 [01:04<00:13,  3.38it/s]\u001b[A\n","Iteration:  83% 217/262 [01:04<00:13,  3.38it/s]\u001b[A\n","Iteration:  83% 218/262 [01:04<00:12,  3.39it/s]\u001b[A\n","Iteration:  84% 219/262 [01:05<00:12,  3.38it/s]\u001b[A\n","Iteration:  84% 220/262 [01:05<00:12,  3.37it/s]\u001b[A\n","Iteration:  84% 221/262 [01:05<00:12,  3.39it/s]\u001b[A\n","Iteration:  85% 222/262 [01:06<00:11,  3.39it/s]\u001b[A\n","Iteration:  85% 223/262 [01:06<00:11,  3.40it/s]\u001b[A\n","Iteration:  85% 224/262 [01:06<00:11,  3.40it/s]\u001b[A\n","Iteration:  86% 225/262 [01:06<00:10,  3.40it/s]\u001b[A\n","Iteration:  86% 226/262 [01:07<00:10,  3.38it/s]\u001b[A\n","Iteration:  87% 227/262 [01:07<00:10,  3.38it/s]\u001b[A\n","Iteration:  87% 228/262 [01:07<00:10,  3.37it/s]\u001b[A\n","Iteration:  87% 229/262 [01:08<00:09,  3.37it/s]\u001b[A\n","Iteration:  88% 230/262 [01:08<00:09,  3.36it/s]\u001b[A\n","Iteration:  88% 231/262 [01:08<00:09,  3.37it/s]\u001b[A\n","Iteration:  89% 232/262 [01:09<00:08,  3.35it/s]\u001b[A\n","Iteration:  89% 233/262 [01:09<00:08,  3.36it/s]\u001b[A\n","Iteration:  89% 234/262 [01:09<00:08,  3.36it/s]\u001b[A\n","Iteration:  90% 235/262 [01:09<00:08,  3.36it/s]\u001b[A\n","Iteration:  90% 236/262 [01:10<00:07,  3.37it/s]\u001b[A\n","Iteration:  90% 237/262 [01:10<00:07,  3.39it/s]\u001b[A\n","Iteration:  91% 238/262 [01:10<00:07,  3.39it/s]\u001b[A\n","Iteration:  91% 239/262 [01:11<00:06,  3.40it/s]\u001b[A\n","Iteration:  92% 240/262 [01:11<00:06,  3.40it/s]\u001b[A\n","Iteration:  92% 241/262 [01:11<00:06,  3.40it/s]\u001b[A\n","Iteration:  92% 242/262 [01:12<00:05,  3.39it/s]\u001b[A\n","Iteration:  93% 243/262 [01:12<00:05,  3.38it/s]\u001b[A\n","Iteration:  93% 244/262 [01:12<00:05,  3.38it/s]\u001b[A\n","Iteration:  94% 245/262 [01:12<00:05,  3.35it/s]\u001b[A\n","Iteration:  94% 246/262 [01:13<00:04,  3.36it/s]\u001b[A\n","Iteration:  94% 247/262 [01:13<00:04,  3.36it/s]\u001b[A\n","Iteration:  95% 248/262 [01:13<00:04,  3.37it/s]\u001b[A\n","Iteration:  95% 249/262 [01:14<00:03,  3.38it/s]\u001b[A\n","Iteration:  95% 250/262 [01:14<00:03,  3.37it/s]\u001b[A\n","Iteration:  96% 251/262 [01:14<00:03,  3.38it/s]\u001b[A\n","Iteration:  96% 252/262 [01:14<00:02,  3.38it/s]\u001b[A\n","Iteration:  97% 253/262 [01:15<00:02,  3.39it/s]\u001b[A\n","Iteration:  97% 254/262 [01:15<00:02,  3.40it/s]\u001b[A\n","Iteration:  97% 255/262 [01:15<00:02,  3.39it/s]\u001b[A\n","Iteration:  98% 256/262 [01:16<00:01,  3.38it/s]\u001b[A\n","Iteration:  98% 257/262 [01:16<00:01,  3.37it/s]\u001b[A\n","Iteration:  98% 258/262 [01:16<00:01,  3.37it/s]\u001b[A\n","Iteration:  99% 259/262 [01:17<00:00,  3.37it/s]\u001b[A\n","Iteration:  99% 260/262 [01:17<00:00,  3.38it/s]\u001b[A\n","Iteration: 100% 261/262 [01:17<00:00,  3.37it/s]\u001b[A\n","Iteration: 100% 262/262 [01:17<00:00,  3.36it/s]\n","Epoch: 100% 1/1 [01:17<00:00, 77.90s/it]\n","03/24/2020 06:19:44 - INFO - __main__ -    global_step = 262, average loss = 3.0098459502212873\n","03/24/2020 06:19:44 - INFO - __main__ -   Saving model checkpoint to bert_ft\n","03/24/2020 06:19:44 - INFO - transformers.configuration_utils -   Configuration saved in bert_ft/config.json\n","03/24/2020 06:19:45 - INFO - transformers.modeling_utils -   Model weights saved in bert_ft/pytorch_model.bin\n","03/24/2020 06:19:45 - INFO - transformers.configuration_utils -   loading configuration file bert_ft/config.json\n","03/24/2020 06:19:45 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": null,\n","  \"do_sample\": false,\n","  \"eos_token_ids\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 28996\n","}\n","\n","03/24/2020 06:19:45 - INFO - transformers.modeling_utils -   loading weights file bert_ft/pytorch_model.bin\n","03/24/2020 06:19:48 - INFO - transformers.tokenization_utils -   Model name 'bert_ft' not found in model shortcut name list (bert-base-uncased, bert-large-uncased, bert-base-cased, bert-large-cased, bert-base-multilingual-uncased, bert-base-multilingual-cased, bert-base-chinese, bert-base-german-cased, bert-large-uncased-whole-word-masking, bert-large-cased-whole-word-masking, bert-large-uncased-whole-word-masking-finetuned-squad, bert-large-cased-whole-word-masking-finetuned-squad, bert-base-cased-finetuned-mrpc, bert-base-german-dbmdz-cased, bert-base-german-dbmdz-uncased, bert-base-finnish-cased-v1, bert-base-finnish-uncased-v1, bert-base-dutch-cased). Assuming 'bert_ft' is a path, a model identifier, or url to a directory containing tokenizer files.\n","03/24/2020 06:19:48 - INFO - transformers.tokenization_utils -   Didn't find file bert_ft/added_tokens.json. We won't load it.\n","03/24/2020 06:19:48 - INFO - transformers.tokenization_utils -   loading file bert_ft/vocab.txt\n","03/24/2020 06:19:48 - INFO - transformers.tokenization_utils -   loading file None\n","03/24/2020 06:19:48 - INFO - transformers.tokenization_utils -   loading file bert_ft/special_tokens_map.json\n","03/24/2020 06:19:48 - INFO - transformers.tokenization_utils -   loading file bert_ft/tokenizer_config.json\n","03/24/2020 06:19:49 - INFO - __main__ -   Evaluate the following checkpoints: ['bert_ft']\n","03/24/2020 06:19:49 - INFO - transformers.configuration_utils -   loading configuration file bert_ft/config.json\n","03/24/2020 06:19:49 - INFO - transformers.configuration_utils -   Model config BertConfig {\n","  \"architectures\": [\n","    \"BertForMaskedLM\"\n","  ],\n","  \"attention_probs_dropout_prob\": 0.1,\n","  \"bos_token_id\": null,\n","  \"do_sample\": false,\n","  \"eos_token_ids\": null,\n","  \"finetuning_task\": null,\n","  \"hidden_act\": \"gelu\",\n","  \"hidden_dropout_prob\": 0.1,\n","  \"hidden_size\": 768,\n","  \"id2label\": {\n","    \"0\": \"LABEL_0\",\n","    \"1\": \"LABEL_1\"\n","  },\n","  \"initializer_range\": 0.02,\n","  \"intermediate_size\": 3072,\n","  \"is_decoder\": false,\n","  \"label2id\": {\n","    \"LABEL_0\": 0,\n","    \"LABEL_1\": 1\n","  },\n","  \"layer_norm_eps\": 1e-12,\n","  \"length_penalty\": 1.0,\n","  \"max_length\": 20,\n","  \"max_position_embeddings\": 512,\n","  \"model_type\": \"bert\",\n","  \"num_attention_heads\": 12,\n","  \"num_beams\": 1,\n","  \"num_hidden_layers\": 12,\n","  \"num_labels\": 2,\n","  \"num_return_sequences\": 1,\n","  \"output_attentions\": false,\n","  \"output_hidden_states\": false,\n","  \"output_past\": true,\n","  \"pad_token_id\": null,\n","  \"pruned_heads\": {},\n","  \"repetition_penalty\": 1.0,\n","  \"temperature\": 1.0,\n","  \"top_k\": 50,\n","  \"top_p\": 1.0,\n","  \"torchscript\": false,\n","  \"type_vocab_size\": 2,\n","  \"use_bfloat16\": false,\n","  \"vocab_size\": 28996\n","}\n","\n","03/24/2020 06:19:49 - INFO - transformers.modeling_utils -   loading weights file bert_ft/pytorch_model.bin\n","03/24/2020 06:19:52 - INFO - __main__ -   Loading features from cached file ./bert_cached_lm_510_deft.test.raw\n","03/24/2020 06:19:52 - INFO - __main__ -   ***** Running evaluation  *****\n","03/24/2020 06:19:52 - INFO - __main__ -     Num examples = 47\n","03/24/2020 06:19:52 - INFO - __main__ -     Batch size = 4\n","Evaluating: 100% 12/12 [00:01<00:00, 10.95it/s]\n","03/24/2020 06:19:53 - INFO - __main__ -   ***** Eval results  *****\n","03/24/2020 06:19:53 - INFO - __main__ -     perplexity = tensor(17.6027)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uqMNSbhMwCeA"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EJtATahguhJR","outputId":"1c726e91-9fef-411b-d3d2-226287e002dc","executionInfo":{"status":"ok","timestamp":1585053936649,"user_tz":-330,"elapsed":13679,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":84,"referenced_widgets":["7c4fb460855246498b31f0d85b5c56dc","d9516bdc7f16491a93694848fdd77cc6","3781b1dcfbd249ce9c4164339fea2dba","177dbe2239aa40b1bc23f01d38b8475d","23a098f0a4f843f0898aebb131a4de2a","e8550d0e921a4a1392e84c066e9b3d18","ecd3ae7ad1f04c21b50ccf36bf06370e","c32bbdc7b8f8434fbf33b9ced9fec6e0"]}},"source":["from keras.preprocessing.sequence import pad_sequences\n","MAX_LEN = 64\n","\n","tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n","\n","def tokenise_pad(df, col):\n","  X = [tokenizer.encode(x, add_special_tokens=True) for x in df[col]]\n","  X = pad_sequences(X, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","  return X\n","\n","\n","X_train = tokenise_pad(train_df, PTEXT_COL)\n","X_dev = tokenise_pad(dev_df, PTEXT_COL)\n","X_test = tokenise_pad(test_df, PTEXT_COL)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7c4fb460855246498b31f0d85b5c56dc","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"QqO4Ng29FpZp","colab_type":"code","colab":{}},"source":["def return_attention_masks(X):\n","  attention_masks = []\n","  for seq in X:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","  attention_masks = np.array(attention_masks)  \n","  return attention_masks"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDoz1nrcF6xb","colab_type":"code","colab":{}},"source":["X_train_masks = return_attention_masks(X_train)\n","X_dev_masks = return_attention_masks(X_dev)\n","X_test_masks = return_attention_masks(X_test)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NmQYwCcWxDQT","colab":{}},"source":["y_train = np.array(train_df[Y_COL])\n","y_dev = np.array(dev_df[Y_COL])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qCrL_HHYxQwa"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oT3_hc6Sw0tw","colab":{}},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","outputId":"e4365da8-d3e5-4709-b963-78046c7b88e4","id":"lK3Nn2vRxdaj","executionInfo":{"status":"ok","timestamp":1585053937818,"user_tz":-330,"elapsed":8763,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n","device"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"jN61H0HrxckC","colab":{}},"source":["from sklearn.utils.extmath import softmax\n","from sklearn.metrics import classification_report, f1_score\n","BATCH_SIZE = 32\n","\n","def flat_accuracy(preds, labels):\n","    preds = softmax(preds)\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","\n","def flat_f1(preds, labels):\n","    preds = softmax(preds)\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, pred_flat)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nmhNm-rdyh7e","colab_type":"code","colab":{}},"source":["X_train = torch.tensor(X_train)\n","X_train_masks = torch.tensor(X_train_masks)\n","y_train = torch.tensor(y_train)\n","\n","train_data = TensorDataset(X_train, X_train_masks, y_train)\n","train_sampler = SequentialSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"uDFvr9c5RjX5","colab_type":"code","colab":{}},"source":["X_dev = torch.tensor(X_dev)\n","X_dev_masks = torch.tensor(X_dev_masks)\n","y_dev = torch.tensor(y_dev)\n","\n","dev_data = TensorDataset(X_dev, X_dev_masks, y_dev)\n","dev_sampler = SequentialSampler(dev_data)\n","dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9GScsKOEiUT","colab_type":"code","colab":{}},"source":["X_test = torch.tensor(X_test)\n","X_test_masks = torch.tensor(X_test_masks)\n","\n","test_data = TensorDataset(X_test, X_test_masks)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"OvLk6S7Y3_bJ","colab_type":"code","outputId":"2cc6841d-f8a4-43d6-ff79-5ebcb21f743a","executionInfo":{"status":"ok","timestamp":1585032025107,"user_tz":-330,"elapsed":557691,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":330}},"source":["from tqdm.notebook import tqdm\n","\n","auto_model = None\n","\n","del auto_model\n","auto_model = BertForSequenceClassification.from_pretrained('./bert_ft', output_attentions=False, num_labels= len(np.unique(y_train)))\n","auto_model.to(device)\n","\n","# Optimizer\n","num_total_steps = 1000\n","num_warmup_steps = 100\n","lr = 5e-6\n","param_optimizer = list(auto_model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","    'weight_decay_rate': 0.01},\n","    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","    'weight_decay_rate': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n","\n","best_loss = None\n","\n","auto_model.train()  \n","tr_loss = 0\n","nb_tr_examples, nb_tr_steps = 0, 0\n","n_epochs = 5\n","\n","for epoch in (range(n_epochs)):  \n","  # Training Loop\n","  auto_model.train()\n","  for step, batch in (enumerate(train_dataloader)):\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","\n","    optimizer.zero_grad()\n","    outputs = auto_model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","\n","    loss, logits = outputs[:2]\n","    loss.backward()\n","    optimizer.step()\n","    \n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","\n","  # Validation Loop\n","      \n","  auto_model.eval()\n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","\n","  yt, yp = [], []\n","  for batch in dev_dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_labels = batch\n","    with torch.no_grad():\n","      outputs = auto_model(b_input_ids, \n","                          token_type_ids=None,\n","                          attention_mask=b_input_mask,\n","                          labels= b_labels)        \n","      loss, logits = outputs[:2]\n","    logits = logits.detach().cpu().numpy()\n","    \n","    preds = softmax(logits)\n","    pred_ids = np.argmax(preds, axis=1).flatten()\n","\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    eval_loss += loss.item()\n","    eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","    yt = yt + label_ids.tolist()\n","    yp = yp + pred_ids.tolist()\n","\n","    nb_eval_steps +=1\n","    \n","  print(\"Epoch {} | Train loss: {} | Validation Loss: {} \".format(epoch,\n","                                                                  tr_loss/nb_tr_steps,\n","                                                                  eval_loss/nb_eval_steps, \n","                                                                ))\n","  if best_loss == None or best_loss > eval_loss/nb_eval_steps:\n","    best_loss = eval_loss/nb_eval_steps\n","    torch.save(auto_model.state_dict(), 'models/BERT_FT.pth')\n","    print(f'Saving model')\n","  \n","\n","print(classification_report(yt, yp))   \n"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Epoch 0 | Train loss: 0.4183622065644998 | Validation Loss: 0.44401021191367396 \n","Saving model\n","Epoch 1 | Train loss: 0.37145041491010744 | Validation Loss: 0.3946092407460566 \n","Saving model\n","Epoch 2 | Train loss: 0.3401215292925017 | Validation Loss: 0.3827417432158082 \n","Saving model\n","Epoch 3 | Train loss: 0.3143910983647305 | Validation Loss: 0.36950094004472095 \n","Saving model\n","Epoch 4 | Train loss: 0.29212781414798983 | Validation Loss: 0.3765012257628971 \n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.97      0.91       582\n","           1       0.90      0.67      0.77       272\n","\n","    accuracy                           0.87       854\n","   macro avg       0.88      0.82      0.84       854\n","weighted avg       0.87      0.87      0.86       854\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DMnwlnuQKuW6","colab_type":"code","outputId":"786acc11-b97d-40a7-ea58-16072db4e041","executionInfo":{"status":"ok","timestamp":1585053980644,"user_tz":-330,"elapsed":38467,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":133,"referenced_widgets":["7912d903764e47738a8c40b6d627e05d","2d77e1582c6d4ddc8efe6fd20eb593a4","953a14af93c245359de08b6d6056305c","2773f7b0a3634a9d944cbb1937359763","3878abaf656b4ddca991a69a1f3d11d9","0df0476c170c43b3adacb4dd8aef910b","78910b4e36e14261886e60c48b428170","047678e5c2cd4149945f8b750ff47681","2655f0f2170448b1a3c03b6eaabd8894","fb104b1dd9ae49b19711c61213547f0d","8fd4da839a274caaa9df337f0c8d81b7","6dc9002c544c458d95af163cda5ea29d","874ba20fb9df426ea2ec09bf369dff3e","4edc6966a8454825a6f631e534ea0e0f","4cc078960e1647c78131161a06f6d6e3","688e28babde74041acc7f4938291c6ce"]}},"source":["auto_model = BertForSequenceClassification.from_pretrained('bert-base-cased', output_attentions=False, num_labels= len(np.unique(y_train)))\n","auto_model.load_state_dict(torch.load('models/BERT_FT.pth'))\n","auto_model.to(device)\n","auto_model.eval()\n","print('Loading best model')\n","\n","yt, yp, p = [], [], []\n","for batch in dev_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","  b_input_ids, b_input_mask, b_labels = batch\n","  with torch.no_grad():\n","    outputs = auto_model(b_input_ids, \n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask,\n","                        labels= b_labels)        \n","    loss, logits = outputs[:2]\n","  logits = logits.detach().cpu().numpy()\n","  preds = softmax(logits)\n","\n","  pred_ids = np.argmax(preds, axis=1).flatten()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","  p = p + preds[:,1].tolist()\n","  yt = yt + label_ids.tolist()\n","  yp = yp + pred_ids.tolist()"],"execution_count":26,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"7912d903764e47738a8c40b6d627e05d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=361, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"2655f0f2170448b1a3c03b6eaabd8894","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=435779157, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Loading best model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"CY-1TaeJLerz","colab_type":"code","outputId":"60de6557-a4ac-4b16-968a-c059509c33a6","executionInfo":{"status":"ok","timestamp":1585053980657,"user_tz":-330,"elapsed":37183,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":206}},"source":["dev_df['Probability'] = p\n","dev_df['Predicted'] = yp\n","dev_df['Loss'] = -dev_df['Label']*np.log2(dev_df['Probability']) - (1-dev_df['Label'])*np.log2(1-dev_df['Probability'])\n","dev_df = dev_df.sort_values(by='Loss', axis=0, ascending=False)\n","dev_df.head()"],"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","      <th>SSentence</th>\n","      <th>Probability</th>\n","      <th>Predicted</th>\n","      <th>Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>653</th>\n","      <td>government</td>\n","      <td>”United States v. Miller , 307 U.S. 174 ( 1939...</td>\n","      <td>1</td>\n","      <td>&lt; government &gt; ”United States v. Miller , 307 ...</td>\n","      <td>0.004499</td>\n","      <td>0</td>\n","      <td>7.796323</td>\n","    </tr>\n","    <tr>\n","      <th>622</th>\n","      <td>government</td>\n","      <td>Toll goods are available to many people , and ...</td>\n","      <td>1</td>\n","      <td>&lt; government &gt; Toll goods are available to man...</td>\n","      <td>0.005660</td>\n","      <td>0</td>\n","      <td>7.464977</td>\n","    </tr>\n","    <tr>\n","      <th>266</th>\n","      <td>physics</td>\n","      <td>These rules are special cases of the laws of c...</td>\n","      <td>1</td>\n","      <td>&lt; physics &gt; These rules are special cases of t...</td>\n","      <td>0.006891</td>\n","      <td>0</td>\n","      <td>7.181119</td>\n","    </tr>\n","    <tr>\n","      <th>736</th>\n","      <td>government</td>\n","      <td>The Mattachine Society often worked with the D...</td>\n","      <td>1</td>\n","      <td>&lt; government &gt; The Mattachine Society often wo...</td>\n","      <td>0.006978</td>\n","      <td>0</td>\n","      <td>7.162982</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>biology</td>\n","      <td>Pathogens include bacteria , protists , fungi ...</td>\n","      <td>1</td>\n","      <td>&lt; biology &gt; Pathogens include bacteria , proti...</td>\n","      <td>0.007308</td>\n","      <td>0</td>\n","      <td>7.096285</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Subject  ...      Loss\n","653  government  ...  7.796323\n","622  government  ...  7.464977\n","266     physics  ...  7.181119\n","736  government  ...  7.162982\n","40      biology  ...  7.096285\n","\n","[5 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"KNgQ7-QFSPny","colab_type":"code","outputId":"25419aa5-1142-43e0-bbee-d0b39bcc2646","executionInfo":{"status":"ok","timestamp":1585053980667,"user_tz":-330,"elapsed":36145,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":211}},"source":["c = 10\n","for i in dev_df['Sentence']:\n","  print(i)\n","  c-=1\n","  if c==0:\n","    break"],"execution_count":28,"outputs":[{"output_type":"stream","text":["”United States v. Miller , 307 U.S. 174 ( 1939 ) .\n","Toll goods are available to many people , and many people can make use of them , but only if they can pay the price .\n","These rules are special cases of the laws of conservation of charge and conservation of energy .\n","The Mattachine Society often worked with the Daughters of Bilitis , a lesbian rights organization .\n","Pathogens include bacteria , protists , fungi and other infectious organisms .\n","The practice of judicial review enabled the law ’s critics to exercise this opportunity , even though their hopes were ultimately dashed when , by a narrow 5 – 4 margin , the Supreme Court upheld the health care law as a constitutional extension of Congress ’s power to tax .\n","Starting in New York in 1790 , the early Supreme Court focused on establishing its rules and procedures and perhaps trying to carve its place as the new government ’s third branch .\n","Brucellosis is an example of a prokaryotic zoonosis that is re - emerging in some regions , and necrotizing fasciitis ( commonly known as flesh - eating bacteria ) has been increasing in virulence for the last 80 years for unknown reasons .\n","Radical Whigs favored broadening the popular participation in political life and pushed for democracy .\n","In social - cognitive theory , the concepts of reciprocal determinism , observational learning , and self - efficacy all play a part in personality development .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"A4VmOKG8k9Pe","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"a0bd20c0-b046-4b98-f676-e645b6d0dcdf","executionInfo":{"status":"ok","timestamp":1585057538438,"user_tz":-330,"elapsed":1417,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["from sklearn.metrics import confusion_matrix, f1_score\n","confusion_matrix(yt, yp), f1_score(yt, yp)"],"execution_count":30,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[561,  21],\n","        [ 89, 183]]), 0.7689075630252102)"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"a8fexQ4eUdUv","colab_type":"text"},"source":["# Test Predictions"]},{"cell_type":"code","metadata":{"id":"8yMA9MSX3_Xy","colab_type":"code","outputId":"0ad9e68a-c84d-4c66-c92b-0d86e5e4f69b","executionInfo":{"status":"ok","timestamp":1584983615015,"user_tz":-330,"elapsed":4062,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["test_preds = []\n","auto_model.load_state_dict(torch.load('models/bert1_ft.pth'))\n","auto_model.eval()\n","print('Loading best model')\n","\n","for batch in test_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","  b_input_ids, b_input_mask = batch\n","  with torch.no_grad():\n","    outputs = auto_model(b_input_ids, \n","                        token_type_ids=None,\n","                        attention_mask=b_input_mask,\n","                        )        \n","    logits = outputs[0]\n","  logits = logits.detach().cpu().numpy()\n","  preds = softmax(logits)[:, 1]        \n","  test_preds = test_preds + preds.tolist()"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Loading best model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"W6FTw6UqzliW","colab_type":"code","colab":{}},"source":["test_df.to_csv('sub/submission_bert_ft_final.csv', index=False)"],"execution_count":0,"outputs":[]}]}