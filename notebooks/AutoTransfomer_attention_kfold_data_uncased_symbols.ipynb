{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"New data AutoTransfomer_attention_kfold.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU","widgets":{"application/vnd.jupyter.widget-state+json":{"4d018b331f1e435fa6b2df6c0f695e44":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_371b986187ba48c1a34e1decb8007e6f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_a77d563cdb464c5681be384dc5451e40","IPY_MODEL_dcc69dbe243d4e7f8e6c63d42ac37a2b"]}},"371b986187ba48c1a34e1decb8007e6f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"a77d563cdb464c5681be384dc5451e40":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_0a668d26e9ae4bd193e608e4e2386ee9","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":231508,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":231508,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_14cb6546f14a444fb22da840de9284c3"}},"dcc69dbe243d4e7f8e6c63d42ac37a2b":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_c6c70eec75b6432897fbd1ae821881ce","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 232k/232k [00:00&lt;00:00, 907kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_ff7e363b676f4af98db6c54c39262a95"}},"0a668d26e9ae4bd193e608e4e2386ee9":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"14cb6546f14a444fb22da840de9284c3":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"c6c70eec75b6432897fbd1ae821881ce":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"ff7e363b676f4af98db6c54c39262a95":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"71a96de6fc004591860b45aa32d18627":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_933c84467f35499a937c1945cc9df938","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_73c3fa52349541be860da532a27f2e91","IPY_MODEL_6d2309d4f2a14726916cae5feab7fa76"]}},"933c84467f35499a937c1945cc9df938":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"73c3fa52349541be860da532a27f2e91":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_ccc5b66615bf4499ad1334a5771f6226","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":313,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":313,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_79ea1c5d896c4c3c83597c66eff2e912"}},"6d2309d4f2a14726916cae5feab7fa76":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_9803716bcaa84b24b3726edd776cc376","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 313/313 [00:00&lt;00:00, 8.01kB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_84f27d65346e45749dbd9c3486e97427"}},"ccc5b66615bf4499ad1334a5771f6226":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"79ea1c5d896c4c3c83597c66eff2e912":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9803716bcaa84b24b3726edd776cc376":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"84f27d65346e45749dbd9c3486e97427":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"67201011e03e4a739d06bd7cba79896c":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_62c6c21f6ee047bcb864ccdb1d837ae0","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_1c3ee2ebe28a4f3699649433450d28eb","IPY_MODEL_a6eb6aab5fce4b7fb10a906a6d3f7529"]}},"62c6c21f6ee047bcb864ccdb1d837ae0":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"1c3ee2ebe28a4f3699649433450d28eb":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_cb380599ba3f4f7dbd5823d4bdc71378","_dom_classes":[],"description":"Downloading","_model_name":"IntProgressModel","bar_style":"success","max":440473133,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":440473133,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_2c0f7cd522d64eb68d61198a4bdd3352"}},"a6eb6aab5fce4b7fb10a906a6d3f7529":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_72e5f651071c402997d471a56fddb015","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":"100% 440M/440M [00:15&lt;00:00, 28.5MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_7e5bf3c11cc7483e99f9e0918b59dee6"}},"cb380599ba3f4f7dbd5823d4bdc71378":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"2c0f7cd522d64eb68d61198a4bdd3352":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"72e5f651071c402997d471a56fddb015":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"7e5bf3c11cc7483e99f9e0918b59dee6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"code","metadata":{"id":"z6TuFfcvZyno","colab_type":"code","outputId":"588e3d91-6f53-4985-d1c0-fbf81899c9eb","executionInfo":{"status":"ok","timestamp":1576297329590,"user_tz":-330,"elapsed":32146,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"03532460980266287093"}},"colab":{"base_uri":"https://localhost:8080/","height":124}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"LWFFLdrJZbNq","colab_type":"code","outputId":"c9016fc3-b17d-4453-a9d9-c18e70da000c","executionInfo":{"status":"ok","timestamp":1576297352373,"user_tz":-330,"elapsed":20041,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"03532460980266287093"}},"colab":{"base_uri":"https://localhost:8080/","height":121}},"source":["! pip install transformers -q"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[?25l\r\u001b[K     |▉                               | 10kB 37.5MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 6.5MB/s eta 0:00:01\r\u001b[K     |██▌                             | 30kB 9.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 40kB 6.0MB/s eta 0:00:01\r\u001b[K     |████▎                           | 51kB 7.4MB/s eta 0:00:01\r\u001b[K     |█████                           | 61kB 8.7MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 9.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 81kB 11.1MB/s eta 0:00:01\r\u001b[K     |███████▋                        | 92kB 12.4MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 102kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 112kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 122kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████                     | 133kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 143kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 153kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 163kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 174kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████▏                | 184kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████                | 194kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 204kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████▊              | 215kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 225kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████▌            | 235kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████▎           | 245kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 256kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 266kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 276kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 286kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▌       | 296kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 307kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 317kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 327kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 337kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▊   | 348kB 9.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 358kB 9.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▍ | 368kB 9.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 378kB 9.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 389kB 9.7MB/s \n","\u001b[K     |████████████████████████████████| 1.0MB 38.3MB/s \n","\u001b[K     |████████████████████████████████| 675kB 64.6MB/s \n","\u001b[K     |████████████████████████████████| 860kB 56.6MB/s \n","\u001b[?25h  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"9W8iuy5iZbN0","colab_type":"code","colab":{}},"source":["import csv\n","import pandas as pd\n","from pathlib import Path\n","import matplotlib.cm as cm\n","from fastai import *\n","from fastai.text import *\n","from fastai.callbacks import *\n","from fastai.metrics import *\n","import numpy as np\n","import pandas as pd\n","\n","from pathlib import Path\n","from typing import *\n","\n","import torch\n","import torch.optim as optim"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"WJUOCfwJ7nG7","colab_type":"code","colab":{}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bDcJAbWQmWmW","colab_type":"code","colab":{}},"source":["seed = 42\n","\n","# python RNG\n","import random\n","random.seed(seed)\n","\n","# pytorch RNGs\n","import torch\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","\n","# numpy RNG\n","import numpy as np\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Pfkl3wOmaRkt","colab_type":"code","colab":{}},"source":["import os\n","os.chdir('/gdrive/My Drive/Definition')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"17X4qG7RZbN-","colab_type":"code","colab":{}},"source":["model_name=\"bert-base-uncased\"\n","#model_name=\"roberta-base\"\n","#model_name=\"xlnet-base-cased\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"9Ad9AScmzi00","colab_type":"code","outputId":"6e3a4043-a79e-4ade-9d57-7780ae99633c","executionInfo":{"status":"ok","timestamp":1576297362980,"user_tz":-330,"elapsed":2044,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"03532460980266287093"}},"colab":{"base_uri":"https://localhost:8080/","height":147}},"source":["merged = pd.read_csv('WCL_data2.csv')\n","merged.head(2)"],"execution_count":8,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>label</th>\n","      <th>Psentence</th>\n","      <th>Length</th>\n","      <th>Dep1</th>\n","      <th>Dep2</th>\n","      <th>DepLabel</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>a pianist   is  a person who plays the piano.</td>\n","      <td>9</td>\n","      <td>pianist is is is person person plays plays piano</td>\n","      <td>a pianist person . a plays who piano the</td>\n","      <td>nsubj ROOT ROOT ROOT attr attr relcl relcl dobj</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0</td>\n","      <td>pingala has a sunlike nature and male energy.</td>\n","      <td>8</td>\n","      <td>has has has nature nature nature nature energy</td>\n","      <td>pingala nature . a sunlike and energy male</td>\n","      <td>ROOT ROOT ROOT dobj dobj dobj dobj conj</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   label  ...                                         DepLabel\n","0      1  ...  nsubj ROOT ROOT ROOT attr attr relcl relcl dobj\n","1      0  ...          ROOT ROOT ROOT dobj dobj dobj dobj conj\n","\n","[2 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":8}]},{"cell_type":"code","metadata":{"id":"_Cggr4LVl1Le","colab_type":"code","colab":{}},"source":["def seq_len(row):\n","  return len(row['Psentence'].split())\n","\n","merged['Length'] = merged.apply(seq_len, axis=1)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oj6xgU_Nl30d","colab_type":"code","outputId":"28658cf8-c104-40b5-b581-854d20da964f","executionInfo":{"status":"ok","timestamp":1576297369905,"user_tz":-330,"elapsed":1767,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"03532460980266287093"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["merged = merged[merged['Length']>4]\n","merged.shape"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(4680, 6)"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"SLBkrbyeZbOp","colab_type":"code","colab":{}},"source":["label_cols = list(set(merged['label']))"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ZI5qRserOi64","colab_type":"text"},"source":["## Transformer"]},{"cell_type":"code","metadata":{"id":"8TBbnX8TZbOF","colab_type":"code","outputId":"ce71051e-b9c3-4921-82a6-8b2624bf3128","executionInfo":{"status":"ok","timestamp":1576297374692,"user_tz":-330,"elapsed":4508,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"03532460980266287093"}},"colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["4d018b331f1e435fa6b2df6c0f695e44","371b986187ba48c1a34e1decb8007e6f","a77d563cdb464c5681be384dc5451e40","dcc69dbe243d4e7f8e6c63d42ac37a2b","0a668d26e9ae4bd193e608e4e2386ee9","14cb6546f14a444fb22da840de9284c3","c6c70eec75b6432897fbd1ae821881ce","ff7e363b676f4af98db6c54c39262a95"]}},"source":[" %tensorflow_version 1.x \n","from transformers import BertTokenizer, GPT2Tokenizer, AutoTokenizer\n","from transformers import BertConfig, BertForSequenceClassification, AutoModel, AutoModelForSequenceClassification\n","\n","tokenizer = AutoTokenizer.from_pretrained(model_name, output_attentions=True)"],"execution_count":12,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"4d018b331f1e435fa6b2df6c0f695e44","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=231508, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uqMNSbhMwCeA","colab_type":"text"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"id":"EJtATahguhJR","colab_type":"code","outputId":"b5e42a8c-efaf-40bb-a37c-b2e1238a24a9","executionInfo":{"status":"ok","timestamp":1576297377425,"user_tz":-330,"elapsed":3776,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"03532460980266287093"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["from keras.preprocessing.sequence import pad_sequences\n","MAX_LEN = 64\n","X = [tokenizer.encode(x, add_special_tokens=True) for x in merged['Psentence']]\n","X = pad_sequences(X, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"g84o6yiZwfBr","colab_type":"code","colab":{}},"source":["attention_masks = []\n","# Create a mask of 1s for each token followed by 0s for padding\n","for seq in X:\n","  seq_mask = [float(i>0) for i in seq]\n","  attention_masks.append(seq_mask)\n","attention_masks = np.array(attention_masks)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"oT3_hc6Sw0tw","colab_type":"code","colab":{}},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n","from sklearn.model_selection import train_test_split"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NmQYwCcWxDQT","colab_type":"code","colab":{}},"source":["y = np.array(merged['label'])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qCrL_HHYxQwa","colab_type":"text"},"source":["# Training"]},{"cell_type":"code","metadata":{"id":"vs29Zck60rpB","colab_type":"code","outputId":"2fc57105-6adb-4314-de4e-2ae318137eb9","executionInfo":{"status":"ok","timestamp":1576297385369,"user_tz":-330,"elapsed":1414,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"03532460980266287093"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n","device"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"code","metadata":{"id":"9mqC5yTxyV3-","colab_type":"code","colab":{}},"source":["from sklearn.utils.extmath import softmax\n","from sklearn.metrics import classification_report, f1_score\n","\n","\n","def flat_accuracy(preds, labels):\n","    preds = softmax(preds)\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","\n","def flat_f1(preds, labels):\n","    preds = softmax(preds)\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, pred_flat)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"EZww_KS_w93w","colab_type":"code","outputId":"f255f53c-53ca-4dc1-9813-561111fde690","executionInfo":{"status":"ok","timestamp":1576298051114,"user_tz":-330,"elapsed":663697,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"03532460980266287093"}},"colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["71a96de6fc004591860b45aa32d18627","933c84467f35499a937c1945cc9df938","73c3fa52349541be860da532a27f2e91","6d2309d4f2a14726916cae5feab7fa76","ccc5b66615bf4499ad1334a5771f6226","79ea1c5d896c4c3c83597c66eff2e912","9803716bcaa84b24b3726edd776cc376","84f27d65346e45749dbd9c3486e97427","67201011e03e4a739d06bd7cba79896c","62c6c21f6ee047bcb864ccdb1d837ae0","1c3ee2ebe28a4f3699649433450d28eb","a6eb6aab5fce4b7fb10a906a6d3f7529","cb380599ba3f4f7dbd5823d4bdc71378","2c0f7cd522d64eb68d61198a4bdd3352","72e5f651071c402997d471a56fddb015","7e5bf3c11cc7483e99f9e0918b59dee6"]}},"source":["from sklearn.model_selection import KFold,StratifiedKFold\n","from tqdm import tqdm\n","\n","auto_model = None\n","\n","kf = StratifiedKFold(10, shuffle=True, random_state=2018)\n","for f,(tr, val) in enumerate(kf.split(X, y)):\n","    print(f'--------------------------------------------------------------------------------Fold # {f}--------------------------------------------------------------------')\n","\n","    X_train, X_val = X[tr], X[val]\n","    y_train, y_val = y[tr], y[val]\n","    X_train_masks, X_val_masks = attention_masks[tr], attention_masks[val]\n","                                         \n","    # Convert all of our data into torch tensors, the required datatype for our model\n","    X_train = torch.tensor(X_train)\n","    X_val = torch.tensor(X_val)\n","\n","    y_train = torch.tensor(y_train)\n","    y_val = torch.tensor(y_val)\n","\n","    X_train_masks = torch.tensor(X_train_masks)\n","    X_val_masks = torch.tensor(X_val_masks)\n","\n","    batch_size = 32\n","\n","    # Create an iterator of our data with torch DataLoader \n","    train_data = TensorDataset(X_train, X_train_masks, y_train)\n","    train_sampler = SequentialSampler(train_data)\n","    train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n","\n","    validation_data = TensorDataset(X_val, X_val_masks, y_val)\n","    validation_sampler = SequentialSampler(validation_data)\n","    validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n","\n","\n","    ## Model\n","    del auto_model\n","    auto_model = AutoModelForSequenceClassification.from_pretrained(model_name, output_attentions=True, num_labels= len(np.unique(y_train)))\n","    auto_model.to(device)\n","\n","    # Optimizer\n","    num_total_steps = 1000\n","    num_warmup_steps = 100\n","    lr = 2e-5\n","    param_optimizer = list(auto_model.named_parameters())\n","    no_decay = ['bias', 'gamma', 'beta']\n","    optimizer_grouped_parameters = [\n","        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","        'weight_decay_rate': 0.01},\n","        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","        'weight_decay_rate': 0.0}\n","    ]\n","    optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n","    \n","\n","    auto_model.train()  \n","    tr_loss = 0\n","    nb_tr_examples, nb_tr_steps = 0, 0\n","    n_epochs = 2\n","\n","    for epoch in (range(n_epochs)):  \n","      # Training Loop\n","      for step, batch in (enumerate(train_dataloader)):\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","\n","        optimizer.zero_grad()\n","        outputs = auto_model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask, labels=b_labels)\n","\n","        loss, logits = outputs[:2]\n","        loss.backward()\n","        optimizer.step()\n","        \n","        tr_loss += loss.item()\n","        nb_tr_examples += b_input_ids.size(0)\n","        nb_tr_steps += 1\n","          \n","      auto_model.eval()\n","      eval_loss, eval_accuracy = 0, 0\n","      nb_eval_steps, nb_eval_examples = 0, 0\n","\n","      # Validation Loop\n","      yt, yp = [], []\n","      for batch in validation_dataloader:\n","        batch = tuple(t.to(device) for t in batch)\n","        b_input_ids, b_input_mask, b_labels = batch\n","        with torch.no_grad():\n","          outputs = auto_model(b_input_ids, \n","                              token_type_ids=None,\n","                              attention_mask=b_input_mask,\n","                              labels= b_labels)        \n","          loss, logits = outputs[:2]\n","        logits = logits.detach().cpu().numpy()\n","        \n","        preds = softmax(logits)\n","        pred_ids = np.argmax(preds, axis=1).flatten()\n","\n","        label_ids = b_labels.to('cpu').numpy()\n","\n","        eval_loss += loss.item()\n","        eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","        yt = yt + label_ids.tolist()\n","        yp = yp + pred_ids.tolist()\n","\n","        nb_eval_steps +=1\n","        \n","      print(\"Epoch {} | Train loss: {} | Validation Loss: {} \".format(epoch,\n","                                                                      tr_loss/nb_tr_steps,\n","                                                                      eval_loss/nb_eval_steps, \n","                                                                    ))\n","    #if epoch == n_epochs:\n","    print(classification_report(yt, yp))   \n"],"execution_count":19,"outputs":[{"output_type":"stream","text":["--------------------------------------------------------------------------------Fold # 0--------------------------------------------------------------------\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"71a96de6fc004591860b45aa32d18627","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=313, style=ProgressStyle(description_width=…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"67201011e03e4a739d06bd7cba79896c","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=440473133, style=ProgressStyle(description_…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n","Epoch 0 | Train loss: 0.1585796523952123 | Validation Loss: 0.09802586423854033 \n","Epoch 1 | Train loss: 0.10284176971728096 | Validation Loss: 0.07202956229448318 \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.98      0.98       281\n","           1       0.97      0.97      0.97       188\n","\n","    accuracy                           0.98       469\n","   macro avg       0.98      0.98      0.98       469\n","weighted avg       0.98      0.98      0.98       469\n","\n","--------------------------------------------------------------------------------Fold # 1--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.17176300339457212 | Validation Loss: 0.07631193213164807 \n","Epoch 1 | Train loss: 0.11623833613173867 | Validation Loss: 0.03781630769371987 \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.99      0.99       281\n","           1       0.98      1.00      0.99       188\n","\n","    accuracy                           0.99       469\n","   macro avg       0.99      0.99      0.99       469\n","weighted avg       0.99      0.99      0.99       469\n","\n","--------------------------------------------------------------------------------Fold # 2--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.18070479352591615 | Validation Loss: 0.09934898391366005 \n","Epoch 1 | Train loss: 0.11528394689120239 | Validation Loss: 0.10180154281357924 \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.95      0.98       281\n","           1       0.94      1.00      0.97       187\n","\n","    accuracy                           0.97       468\n","   macro avg       0.97      0.98      0.97       468\n","weighted avg       0.97      0.97      0.97       468\n","\n","--------------------------------------------------------------------------------Fold # 3--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.18014088559500646 | Validation Loss: 0.09197046036521593 \n","Epoch 1 | Train loss: 0.11167516782315391 | Validation Loss: 0.06234870031476021 \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.99      0.99       281\n","           1       0.98      0.98      0.98       187\n","\n","    accuracy                           0.99       468\n","   macro avg       0.98      0.98      0.98       468\n","weighted avg       0.99      0.99      0.99       468\n","\n","--------------------------------------------------------------------------------Fold # 4--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.2069008865986358 | Validation Loss: 0.07412119209766388 \n","Epoch 1 | Train loss: 0.1302651965260421 | Validation Loss: 0.06263532070443034 \n","              precision    recall  f1-score   support\n","\n","           0       0.98      0.99      0.99       281\n","           1       0.98      0.97      0.98       187\n","\n","    accuracy                           0.98       468\n","   macro avg       0.98      0.98      0.98       468\n","weighted avg       0.98      0.98      0.98       468\n","\n","--------------------------------------------------------------------------------Fold # 5--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.17916681683819854 | Validation Loss: 0.12167925909161567 \n","Epoch 1 | Train loss: 0.1151446343953439 | Validation Loss: 0.11211020909249783 \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.96      0.97       281\n","           1       0.94      0.98      0.96       187\n","\n","    accuracy                           0.97       468\n","   macro avg       0.97      0.97      0.97       468\n","weighted avg       0.97      0.97      0.97       468\n","\n","--------------------------------------------------------------------------------Fold # 6--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.17408105881997582 | Validation Loss: 0.08273115791380406 \n","Epoch 1 | Train loss: 0.11768429520518774 | Validation Loss: 0.07737030809124311 \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.98       281\n","           1       0.97      0.98      0.97       187\n","\n","    accuracy                           0.98       468\n","   macro avg       0.98      0.98      0.98       468\n","weighted avg       0.98      0.98      0.98       468\n","\n","--------------------------------------------------------------------------------Fold # 7--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.16324425257290853 | Validation Loss: 0.1190014439324538 \n","Epoch 1 | Train loss: 0.10938814359498351 | Validation Loss: 0.09240078193446001 \n","              precision    recall  f1-score   support\n","\n","           0       0.97      0.98      0.98       281\n","           1       0.97      0.96      0.96       187\n","\n","    accuracy                           0.97       468\n","   macro avg       0.97      0.97      0.97       468\n","weighted avg       0.97      0.97      0.97       468\n","\n","--------------------------------------------------------------------------------Fold # 8--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.175253697177113 | Validation Loss: 0.06636484302580356 \n","Epoch 1 | Train loss: 0.10790694117983521 | Validation Loss: 0.071641664331158 \n","              precision    recall  f1-score   support\n","\n","           0       1.00      0.97      0.98       280\n","           1       0.96      0.99      0.98       187\n","\n","    accuracy                           0.98       467\n","   macro avg       0.98      0.98      0.98       467\n","weighted avg       0.98      0.98      0.98       467\n","\n","--------------------------------------------------------------------------------Fold # 9--------------------------------------------------------------------\n","Epoch 0 | Train loss: 0.16350052301122836 | Validation Loss: 0.09092701325813929 \n","Epoch 1 | Train loss: 0.10061864607092558 | Validation Loss: 0.07151662999143203 \n","              precision    recall  f1-score   support\n","\n","           0       0.99      0.98      0.98       280\n","           1       0.97      0.98      0.98       187\n","\n","    accuracy                           0.98       467\n","   macro avg       0.98      0.98      0.98       467\n","weighted avg       0.98      0.98      0.98       467\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"_N3pLdh6qr6L","colab":{}},"source":["torch.save(auto_model.state_dict(), 'models/bert_attn_97_10fold.pth')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"G-KIjKKnqrBU","colab":{}},"source":["# auto_model.load_state_dict(torch.load('models/bert_new.pth'))\n","# print(f'Done')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o_beEt5mfXue","colab_type":"text"},"source":["# Analysis of model"]},{"cell_type":"code","metadata":{"id":"EZ_68nmOUNVU","colab_type":"code","colab":{}},"source":["y_pred = []\n","y_true = []\n","\n","x = []\n","\n","for batch in tqdm(validation_dataloader):\n","  \n","  batch = tuple(t.to(device) for t in batch)\n","  b_input_ids, b_input_mask, b_labels = batch\n","  with torch.no_grad():\n","    outputs = auto_model(b_input_ids, token_type_ids=None, attention_mask=b_input_mask)    \n","    logits = outputs[0]\n","\n","  logits = logits.detach().cpu().numpy()\n","  label_ids = b_labels.to('cpu').numpy()\n","  prob = softmax(logits)\n","  pred = np.argmax(prob, axis=1)\n","  for i in b_input_ids:\n","    z = []\n","    for j in i:\n","      z.append(j.item())\n","    x.append(z)\n","  [y_pred.append(i) for i in prob[:,1]]\n","  [y_true.append(i) for i in label_ids]"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7qvWPxyffOrX","colab_type":"code","colab":{}},"source":["df = pd.DataFrame({'Prob':y_pred, 'class':y_true, 'input':x})\n","df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"scxdXvxWiUUE","colab_type":"code","colab":{}},"source":["#tok1.decode(df.loc[1,'input'])\n","\n","df['sentence'] = df['input'].apply(lambda x:tok1.decode(x))\n","df.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QTEFnauFfjIU","colab_type":"code","colab":{}},"source":["df['Correct'] = ((df['Prob']>=0.5)*1 == df['class'])*1\n","w = df[df['Correct']==0].copy()\n","w.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"u1uAodpWfn30","colab_type":"code","colab":{}},"source":["w.sort_values('Prob', inplace=True)\n","w.shape"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HEjp4fnLfrsF","colab_type":"code","colab":{}},"source":["fp = w[w['class']==0].reset_index(drop=True)\n","fn = w[w['class']==1].reset_index(drop=True)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"FO2WNg60mfnu","colab_type":"code","colab":{}},"source":["fp.head()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VqmaZYjHmOCY","colab_type":"code","colab":{}},"source":["for i in range(10):\n","  print(fp.loc[i,'sentence'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ttaXoFKjmu7v","colab_type":"code","colab":{}},"source":["for i in range(10):\n","  print(fn.loc[i,'sentence'])"],"execution_count":0,"outputs":[]}]}