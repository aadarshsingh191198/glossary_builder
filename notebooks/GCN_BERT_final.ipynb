{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"GCN_BERT_final.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.1"},"widgets":{"application/vnd.jupyter.widget-state+json":{"b2fd1a5d6fb046a8b421361bb7d63c4d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_fb4af7ad3b6f4903926f1f63a9340f1f","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_7795f83dac624252ad1488239beee959","IPY_MODEL_a479b88fc9fe4b698728ea3e5e5b25bb"]}},"fb4af7ad3b6f4903926f1f63a9340f1f":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"7795f83dac624252ad1488239beee959":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_c5bcf032b6aa4911b32059ac494f4c25","_dom_classes":[],"description":"Downloading: 100%","_model_name":"IntProgressModel","bar_style":"success","max":213450,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":213450,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_e69c2e7f57f44c8897f9717c16a26ea1"}},"a479b88fc9fe4b698728ea3e5e5b25bb":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_40fcf44f84c7468b97c788826d8b3562","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 213k/213k [00:00&lt;00:00, 1.95MB/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_f82463032f724bd2858f21297c7e9575"}},"c5bcf032b6aa4911b32059ac494f4c25":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"e69c2e7f57f44c8897f9717c16a26ea1":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"40fcf44f84c7468b97c788826d8b3562":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"f82463032f724bd2858f21297c7e9575":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"9ebf2289e76e4723b50fadc321eab9fd":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_6248f60279714fbd9f906c5a548dbaf6","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_61f4aea5de844f72861652d2e3bd3632","IPY_MODEL_b813ed138af94fb6a0defbb21403be02"]}},"6248f60279714fbd9f906c5a548dbaf6":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"61f4aea5de844f72861652d2e3bd3632":{"model_module":"@jupyter-widgets/controls","model_name":"IntProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_d2e1495b188642c885df5db556468624","_dom_classes":[],"description":"100%","_model_name":"IntProgressModel","bar_style":"success","max":17461,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":17461,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_54e1279395b34166902da4d939f39873"}},"b813ed138af94fb6a0defbb21403be02":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_2c3f6f9fc1014218a18225858af2eb71","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 17461/17461 [04:35&lt;00:00, 63.34it/s]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_272da6549b324754ad70ac68e1a98b5c"}},"d2e1495b188642c885df5db556468624":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"54e1279395b34166902da4d939f39873":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2c3f6f9fc1014218a18225858af2eb71":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"272da6549b324754ad70ac68e1a98b5c":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}}},"cells":[{"cell_type":"markdown","metadata":{"id":"LJdyXXq9Kewe","colab_type":"text"},"source":["## Start"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"z6TuFfcvZyno","outputId":"9bdffd0f-2a45-4ae7-be53-de352183e088","colab":{"base_uri":"https://localhost:8080/","height":124},"executionInfo":{"status":"ok","timestamp":1585052680459,"user_tz":-330,"elapsed":47620,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["from google.colab import drive\n","drive.mount('/gdrive')"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"LWFFLdrJZbNq","outputId":"101439c3-a106-4302-9354-2f247c19c28f","colab":{"base_uri":"https://localhost:8080/","height":156},"executionInfo":{"status":"ok","timestamp":1585052708938,"user_tz":-330,"elapsed":33404,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["! pip install transformers -q\n","! pip install dgl-cu100 -q\n","! pip install word2vec -q"],"execution_count":2,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 501kB 2.8MB/s \n","\u001b[K     |████████████████████████████████| 3.7MB 10.2MB/s \n","\u001b[K     |████████████████████████████████| 1.0MB 39.1MB/s \n","\u001b[K     |████████████████████████████████| 870kB 45.6MB/s \n","\u001b[?25h  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","\u001b[K     |████████████████████████████████| 16.2MB 200kB/s \n","\u001b[K     |████████████████████████████████| 61kB 2.0MB/s \n","\u001b[?25h  Building wheel for word2vec (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9W8iuy5iZbN0","colab":{"base_uri":"https://localhost:8080/","height":72},"outputId":"74f38917-323b-4434-f462-4e8b3553f862","executionInfo":{"status":"ok","timestamp":1585052715365,"user_tz":-330,"elapsed":39402,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["import csv\n","import re\n","import pandas as pd\n","from pathlib import Path\n","import matplotlib.cm as cm\n","from fastai import *\n","from fastai.text import *\n","from fastai.callbacks import *\n","from fastai.metrics import *\n","import numpy as np\n","import pandas as pd\n","\n","from pathlib import Path\n","from typing import *\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.optim as optim\n","import dgl\n","import word2vec"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/__init__.py:15: FutureWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n","  warnings.warn(msg, category=FutureWarning)\n"],"name":"stderr"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"WJUOCfwJ7nG7","colab":{}},"source":["import warnings\n","warnings.filterwarnings('ignore')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"bDcJAbWQmWmW","colab":{}},"source":["seed = 42\n","\n","# python RNG\n","import random\n","random.seed(seed)\n","\n","# pytorch RNGs\n","import torch\n","torch.manual_seed(seed)\n","torch.backends.cudnn.deterministic = True\n","if torch.cuda.is_available(): torch.cuda.manual_seed_all(seed)\n","\n","# numpy RNG\n","import numpy as np\n","np.random.seed(seed)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"Pfkl3wOmaRkt","outputId":"8e862e6f-8363-4c50-8188-15492d4c0bd2","colab":{"base_uri":"https://localhost:8080/","height":295},"executionInfo":{"status":"ok","timestamp":1585052719805,"user_tz":-330,"elapsed":42218,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["import os\n","os.chdir('/gdrive/My Drive/DEFINITION EXTRACTION/DEFT_Updated')\n","! ls"],"execution_count":6,"outputs":[{"output_type":"stream","text":["BERT_attention_kfold.ipynb\t   rbert_ft\n","bert_cached_lm_510_deft.test.raw   roberta_cached_lm_510_deft.test.raw\n","bert_cached_lm_510_deft.train.raw  roberta_cached_lm_510_deft.train.raw\n","bert_ft\t\t\t\t   RobertaLM_GB_kfold.ipynb\n","catboost_info\t\t\t   roberta_tuned_test.npy\n","deft.test.raw\t\t\t   roberta_tuned_train.npy\n","deft.train.raw\t\t\t   runs\n","DualXLNet_attention_kfold.ipynb    sub\n","GCN_BERT_attention_kfold.ipynb\t   task1_dev.csv\n","GCN_BERT_dependency_kfold.ipynb    task1_test.csv\n","GCN_BERT_final.ipynb\t\t   task1_train.csv\n","gcn_dep.ipynb\t\t\t   train_lm.py\n","gcn.ipynb\t\t\t   vocab.txt\n","gcn_model.pkl\t\t\t   WCL_cased_symbols.csv\n","glove.6B.200d.vec.txt\t\t   XLNET_attention_kfold.ipynb\n","models\t\t\t\t   XLNET_GCN_attention_kfold.ipynb\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"17X4qG7RZbN-","colab":{}},"source":["model_name=\"bert-base-cased\"\n","# model_name=\"roberta-base\"\n","# model_name=\"xlnet-base-cased\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gHkuwclg5EFy","colab_type":"code","colab":{}},"source":["TEXT_COL = 'Sentence'\n","Y_COL = 'Label'"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"wxp-rwB2jm4_","colab_type":"code","colab":{}},"source":["import re\n","def multi_replace(chars_to_replace, char_to_place, from_string):\n","    for char in chars_to_replace:\n","        from_string = from_string.replace(char,char_to_place)\n","    return from_string\n","\n","def preprocessing(sentence):\n","    remove_punct = multi_replace(',“”’.-{}[]()=+_!@#$%^&*<>?/|\\\\~`:;\"','',sentence)\n","    return remove_punct\n","\n","def load_data(file):\n","    df = pd.read_csv(file)\n","    # removing initial numbers\n","    df[TEXT_COL] = df[TEXT_COL].apply(lambda x : re.findall('^\\s*\\d*\\s*\\.?\\s*(.*)',x)[0])\n","    # preprocessing\n","    # df[TEXT_COL] = df[TEXT_COL].apply(preprocessing)\n","    return df\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9Ad9AScmzi00","outputId":"eebcf9b6-9210-41a9-86a9-b05d0a87ec8b","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1585052720884,"user_tz":-330,"elapsed":41213,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["train_df = load_data('task1_train.csv')\n","train_df.head(2)"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>biology</td>\n","      <td>Science includes such diverse fields as astron...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>biology</td>\n","      <td>However , those fields of science related to t...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Subject                                           Sentence  Label\n","0  biology  Science includes such diverse fields as astron...      0\n","1  biology  However , those fields of science related to t...      1"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"id":"EfRriLZ41WDb","colab_type":"code","outputId":"ec80b924-6534-46c6-8838-fee9a8f144a4","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1585052721307,"user_tz":-330,"elapsed":41109,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["dev_df = load_data('task1_dev.csv')\n","dev_df.head(2)"],"execution_count":11,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>biology</td>\n","      <td>It becomes clear from this definition that the...</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>biology</td>\n","      <td>The scientific method is a method of research ...</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Subject                                           Sentence  Label\n","0  biology  It becomes clear from this definition that the...      0\n","1  biology  The scientific method is a method of research ...      1"]},"metadata":{"tags":[]},"execution_count":11}]},{"cell_type":"code","metadata":{"id":"Rn97INefxSRk","colab_type":"code","outputId":"f250022c-8b37-4df3-ffe5-92b38d4f84b5","colab":{"base_uri":"https://localhost:8080/","height":112},"executionInfo":{"status":"ok","timestamp":1585052721311,"user_tz":-330,"elapsed":40637,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["test_df = load_data('task1_test.csv')\n","test_df.head(2)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label\\n</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>biology</td>\n","      <td>Living things are highly organized and structu...</td>\n","      <td>NaN</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>biology</td>\n","      <td>The atom is the smallest and most fundamental ...</td>\n","      <td>NaN</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   Subject                                           Sentence  Label\\n\n","0  biology  Living things are highly organized and structu...      NaN\n","1  biology  The atom is the smallest and most fundamental ...      NaN"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"KoIuR9xTQpLz","colab_type":"text"},"source":["## GCN"]},{"cell_type":"code","metadata":{"id":"nIwAE3NhQokQ","colab_type":"code","outputId":"ccc90840-cd6c-4b8f-e584-e6e058963d5d","colab":{"base_uri":"https://localhost:8080/","height":81},"executionInfo":{"status":"ok","timestamp":1585052727044,"user_tz":-330,"elapsed":45135,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["from keras.preprocessing.sequence import pad_sequences\n","\n","class DataHelper(object):\n","    def __init__(self, df, mode='train', vocab=None):\n","        self.mode = mode\n","        \n","        self.df = df\n","        if self.mode=='train':\n","          content, label = self.get_content()\n","          self.label = self.label_to_onehot(label)\n","\n","        else:\n","          content = self.get_content()\n","        \n","        if vocab is None:\n","            self.vocab = []\n","            try:\n","                print(f'Vocab file found')\n","                self.get_vocab()\n","            except FileNotFoundError:\n","                self.build_vocab(content, min_count=5)\n","        else:\n","            self.vocab = vocab\n","\n","        self.d = dict(zip(self.vocab, range(len(self.vocab))))\n","        self.rev_d = { v:k for k,v in self.d.items()}\n","        self.content = [list(map(lambda x: self.word2id(x), doc.split(' '))) for doc in content]\n","        self.lengths = [[len(s)] for s in self.content]\n","        self.content = pad_sequences(self.content, maxlen=64, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","\n","\n","    def label_to_onehot(self, label_str):\n","      return np.array(self.df[Y_COL])\n","        \n","    def get_content(self):\n","        if self.mode=='train':\n","          return list(self.df[TEXT_COL]), list(self.df[Y_COL])\n","        else:\n","          return list(self.df[TEXT_COL])\n","\n","    def word2id(self, word):\n","        try:\n","            result = self.d[word]\n","        except KeyError:\n","            result = self.d['UNK']\n","        return result\n","\n","    def get_vocab(self):\n","        with open('vocab-5.txt') as f:\n","            vocab = f.read()\n","            self.vocab = vocab.split('\\n')\n","\n","    def build_vocab(self, content, min_count=10):\n","        vocab = []\n","        for c in content:\n","            words = c.split(' ')\n","            for word in words:\n","                if word not in vocab:\n","                    vocab.append(word)\n","        freq = dict(zip(vocab, [0 for i in range(len(vocab))]))\n","        for c in content:\n","            words = c.split(' ')\n","            for word in words:\n","                freq[word] += 1\n","        results = []\n","        for word in freq.keys():\n","            if freq[word] < min_count:\n","                continue\n","            else:\n","                results.append(word)\n","        results.insert(0, 'UNK')\n","        with open('vocab.txt', 'w') as f:\n","            f.write('\\n'.join(results))\n","        self.vocab = results\n","\n","    def count_word_freq(self, content):\n","        freq = dict(zip(self.vocab, [0 for i in range(len(self.vocab))]))\n","        for c in content:\n","            words = c.split(' ')\n","            for word in words:\n","                freq[word] += 1\n","        with open('freq.csv', 'w') as f:\n","            writer = csv.writer(f)\n","            results = list(zip(freq.keys(), freq.values()))\n","            writer.writerows(results)\n","\n","    def batch_iter(self, batch_size, num_epoch):\n","        for i in range(num_epoch):\n","            num_per_epoch = int(len(self.content) / batch_size)\n","            for batch_id in range(num_per_epoch):\n","                start = batch_id * batch_size\n","                end = min((batch_id + 1) * batch_size, len(self.content))\n","                content = self.content[start:end]\n","                label = self.label[start:end]\n","                yield (content), torch.LongTensor(label).cuda(), i\n"],"execution_count":13,"outputs":[{"output_type":"stream","text":["Using TensorFlow backend.\n"],"name":"stderr"},{"output_type":"display_data","data":{"text/html":["<p style=\"color: red;\">\n","The default version of TensorFlow in Colab will soon switch to TensorFlow 2.x.<br>\n","We recommend you <a href=\"https://www.tensorflow.org/guide/migrate\" target=\"_blank\">upgrade</a> now \n","or ensure your notebook will continue to use TensorFlow 1.x via the <code>%tensorflow_version 1.x</code> magic:\n","<a href=\"https://colab.research.google.com/notebooks/tensorflow_version.ipynb\" target=\"_blank\">more info</a>.</p>\n"],"text/plain":["<IPython.core.display.HTML object>"]},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"evBYVJxYQ-JJ","colab_type":"code","outputId":"abc88f44-8a9b-406c-f403-86009d3e6879","colab":{"base_uri":"https://localhost:8080/","height":69},"executionInfo":{"status":"ok","timestamp":1585052746717,"user_tz":-330,"elapsed":64061,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["train_data_helper = DataHelper(train_df, mode='train')\n","dev_data_helper = DataHelper(dev_df, mode='train')\n","test_data_helper = DataHelper(test_df, mode='test')"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Vocab file found\n","Vocab file found\n","Vocab file found\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"ZI5qRserOi64"},"source":["## Transformer"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"8TBbnX8TZbOF","outputId":"b5377b86-23ed-4b30-afa3-3c01a3a7751b","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["b2fd1a5d6fb046a8b421361bb7d63c4d","fb4af7ad3b6f4903926f1f63a9340f1f","7795f83dac624252ad1488239beee959","a479b88fc9fe4b698728ea3e5e5b25bb","c5bcf032b6aa4911b32059ac494f4c25","e69c2e7f57f44c8897f9717c16a26ea1","40fcf44f84c7468b97c788826d8b3562","f82463032f724bd2858f21297c7e9575"]},"executionInfo":{"status":"ok","timestamp":1585052747226,"user_tz":-330,"elapsed":63315,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":[" %tensorflow_version 1.x \n","from transformers import *\n","tokenizer = BertTokenizer.from_pretrained(model_name, output_attentions=True)"],"execution_count":15,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"b2fd1a5d6fb046a8b421361bb7d63c4d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, description='Downloading', max=213450, style=ProgressStyle(description_wid…"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"uqMNSbhMwCeA"},"source":["## Preprocessing"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EJtATahguhJR","colab":{}},"source":["from keras.preprocessing.sequence import pad_sequences\n","MAX_LEN = 64\n","\n","def tokenise_pad(df):\n","  X = [tokenizer.encode(x, add_special_tokens=True) for x in df[TEXT_COL]]\n","  X = pad_sequences(X, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n","  return X\n","\n","\n","X_train = tokenise_pad(train_df)\n","X_dev = tokenise_pad(dev_df)\n","X_test = tokenise_pad(test_df)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QqO4Ng29FpZp","colab_type":"code","colab":{}},"source":["def return_attention_masks(X):\n","  attention_masks = []\n","  for seq in X:\n","    seq_mask = [float(i>0) for i in seq]\n","    attention_masks.append(seq_mask)\n","  attention_masks = np.array(attention_masks)  \n","  return attention_masks"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"nDoz1nrcF6xb","colab_type":"code","colab":{}},"source":["X_train_masks = return_attention_masks(X_train)\n","X_dev_masks = return_attention_masks(X_dev)\n","X_test_masks = return_attention_masks(X_test)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"NmQYwCcWxDQT","colab":{}},"source":["y_train = np.array(train_df[Y_COL])\n","y_dev = np.array(dev_df[Y_COL])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"colab_type":"code","id":"oT3_hc6Sw0tw","colab":{}},"source":["import torch\n","from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"02ZqMPeySpGS","colab_type":"text"},"source":["## Models"]},{"cell_type":"code","metadata":{"id":"A6iNu714VUUK","colab_type":"code","colab":{}},"source":["def cal_PMI(helper, window_size=20):\n","    content, _ = helper.get_content()\n","    pair_count_matrix = np.zeros((len(helper.vocab), len(helper.vocab)), dtype=int)\n","    word_count =np.zeros(len(helper.vocab), dtype=int)\n","\n","    for sentence in tqdm(content):\n","        sentence = sentence.split(' ')\n","        for i, word in enumerate(sentence):\n","            try:\n","                word_count[helper.d[word]] += 1\n","            except KeyError:\n","                continue\n","            start_index = max(0, i - window_size)\n","            end_index = min(len(sentence), i + window_size)\n","            for j in range(start_index, end_index):\n","                if i == j:\n","                    continue\n","                else:\n","                    target_word = sentence[j]\n","                    try:\n","                        pair_count_matrix[helper.d[word], helper.d[target_word]] += 1\n","                    except KeyError:\n","                        continue\n","\n","    total_count = np.sum(word_count)\n","    word_count = word_count / total_count\n","    pair_count_matrix = pair_count_matrix / total_count\n","\n","    pmi_matrix = np.zeros((len(helper.vocab), len(helper.vocab)), dtype=float)\n","    for i in range(len(helper.vocab)):\n","        for j in range(len(helper.vocab)):\n","            pmi_matrix[i, j] = np.log(\n","                pair_count_matrix[i, j] / (word_count[i] * word_count[j])\n","            )\n","\n","    pmi_matrix = np.nan_to_num(pmi_matrix)\n","\n","    pmi_matrix = np.maximum(pmi_matrix, 0.0)\n","\n","    edges_weights = [0.0]\n","    count = 1\n","    edges_mappings = np.zeros((len(helper.vocab), len(helper.vocab)), dtype=int)\n","    for i in range(len(helper.vocab)):\n","        for j in range(len(helper.vocab)):\n","            if pmi_matrix[i, j] != 0:\n","                edges_weights.append(pmi_matrix[i, j])\n","                edges_mappings[i, j] = count\n","                count += 1\n","\n","    edges_weights = np.array(edges_weights)\n","\n","    edges_weights = edges_weights.reshape(-1, 1)\n","    # print(edges_weights.shape)\n","    edges_weights = torch.Tensor(edges_weights)\n","\n","    return edges_weights, edges_mappings, count\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QZsx152OT82_","colab_type":"code","colab":{}},"source":["def gcn_msg(edge):\n","    return {'m': edge.src['h'], 'w': edge.data['w']}\n","\n","\n","def gcn_reduce(node):\n","    w = node.mailbox['w']\n","\n","    new_hidden = torch.mul(w, node.mailbox['m'])\n","\n","    new_hidden,_ = torch.max(new_hidden, 1)\n","\n","    node_eta = torch.sigmoid(node.data['eta'])\n","    # node_eta = F.leaky_relu(node.data['eta'])\n","\n","    # new_hidden = node_eta * node.data['h'] + (1 - node_eta) * new_hidden\n","    # print(new_hidden.shape)\n","\n","    return {'h': new_hidden}\n","\n","\n","class GCNModel(torch.nn.Module):\n","    def __init__(self,\n","                 hidden_size_node,\n","                 vocab,\n","                 n_gram,\n","                 edges_num,\n","                 edges_matrix,\n","                 max_length=350,\n","                 trainable_edges=True,\n","                 pmi=None,\n","                 cuda=True\n","                 ):\n","        super(GCNModel, self).__init__()\n","\n","        self.is_cuda = cuda\n","        self.vocab = vocab\n","        \n","        self.seq_edge_w = torch.nn.Embedding(edges_num, 1)\n","        print(edges_num)\n","        print(pmi.shape)\n","\n","        self.node_hidden = torch.nn.Embedding(len(vocab), hidden_size_node)\n","        \n","        self.seq_edge_w = torch.nn.Embedding.from_pretrained(pmi, freeze=True)\n","            \n","        self.edges_num = edges_num\n","        if trainable_edges:\n","            self.seq_edge_w = torch.nn.Embedding.from_pretrained(torch.ones(edges_num, 1), freeze=False)\n","        else:\n","            self.seq_edge_w = torch.nn.Embedding.from_pretrained(pmi, freeze=True)\n","\n","        self.hidden_size_node = hidden_size_node\n","\n","        self.node_hidden.weight.data.copy_(torch.tensor(self.load_word2vec('glove.6B.200d.vec.txt')))\n","        self.node_hidden.weight.requires_grad = True\n","\n","        self.len_vocab = len(vocab)\n","\n","        self.ngram = n_gram\n","        self.d = dict(zip(self.vocab, range(len(self.vocab))))\n","        self.max_length = max_length\n","        self.edges_matrix = edges_matrix\n","\n","        self.dropout = torch.nn.Dropout(0.5)\n","        self.activation = torch.nn.ReLU()\n","\n","        \n","\n","    def word2id(self, word):\n","        try:\n","            result = self.d[word]\n","        except KeyError:\n","            result = self.d['UNK']\n","\n","        return result\n","\n","    def load_word2vec(self, word2vec_file):\n","        model = word2vec.load(word2vec_file)\n","        embedding_matrix = []\n","        for word in self.vocab:\n","            try:\n","                embedding_matrix.append(model[word])\n","            except KeyError:\n","                # print(word)\n","                embedding_matrix.append(model['the'])\n","        embedding_matrix = np.array(embedding_matrix)\n","        return embedding_matrix\n","\n","    \n","\n","    def add_seq_edges(self, doc_ids: list, old_to_new: dict):\n","        edges = []\n","        old_edge_id = []\n","        for index, src_word_old in enumerate(doc_ids):\n","            src = old_to_new[int(src_word_old.item())]\n","            for i in range(max(0, index - self.ngram), min(index + self.ngram + 1, len(doc_ids))):\n","                dst_word_old = doc_ids[i].item()\n","                dst = old_to_new[dst_word_old]\n","\n","                # - first connect the new sub_graph\n","                edges.append([src, dst])\n","                # - then get the hidden from parent_graph\n","                old_edge_id.append(self.edges_matrix[src_word_old, dst_word_old])\n","\n","            # self circle\n","            edges.append([src, src])\n","            old_edge_id.append(self.edges_matrix[src_word_old, src_word_old])\n","        return edges, old_edge_id\n","\n","    def seq_to_graph(self, doc_ids: list, doc_length) -> dgl.DGLGraph():\n","        doc_ids = doc_ids[0:doc_length]\n","        if len(doc_ids) > self.max_length:\n","            doc_ids = doc_ids[:self.max_length]\n","        local_vocab = set(doc_ids)\n","\n","        old_to_new = {}\n","        for i,j in enumerate(local_vocab):\n","          old_to_new[j.item()] = i\n","        # old_to_new = dict(zip(local_vocab, range(len(local_vocab))))\n","\n","        # print(old_to_new)\n","\n","        if self.is_cuda:\n","            local_vocab = torch.tensor(list(local_vocab)).cuda()\n","        else:\n","            local_vocab = torch.tensor(list(local_vocab))\n","\n","        sub_graph = dgl.DGLGraph()\n","\n","        sub_graph.add_nodes(len(local_vocab))\n","        local_node_hidden = self.node_hidden(local_vocab)\n","\n","        sub_graph.ndata['h'] = local_node_hidden\n","\n","        seq_edges, seq_old_edges_id = self.add_seq_edges(doc_ids, old_to_new)\n","\n","        edges, old_edge_id = [], []\n","        \n","        edges.extend(seq_edges)\n","\n","        old_edge_id.extend(seq_old_edges_id)\n","\n","        if self.is_cuda:\n","            old_edge_id = torch.LongTensor(old_edge_id).cuda()\n","        else:\n","            old_edge_id = torch.LongTensor(old_edge_id)\n","\n","        srcs, dsts = zip(*edges)\n","        sub_graph.add_edges(srcs, dsts)\n","        try:\n","            seq_edges_w = self.seq_edge_w(old_edge_id)\n","        except RuntimeError:\n","            print(old_edge_id)\n","        sub_graph.edata['w'] = seq_edges_w\n","\n","        return sub_graph\n","\n","    def forward(self, doc_ids, doc_lengths):\n","        sub_graphs = [self.seq_to_graph(doc, length) for doc, length in zip(doc_ids, doc_lengths)]\n","\n","        batch_graph = dgl.batch(sub_graphs)\n","\n","        batch_graph.update_all(\n","            message_func=dgl.function.src_mul_edge('h', 'w', 'weighted_message'),\n","            reduce_func=dgl.function.max('weighted_message', 'h')\n","        )\n","\n","        h1 = dgl.sum_nodes(batch_graph, feat='h')\n","        drop1 = self.dropout(h1)\n","        act1 = self.activation(drop1)\n","        # l = self.Linear(act1)\n","        return act1\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"mwbhkwuDSoUu","colab_type":"code","colab":{}},"source":["class BertFeature(BertPreTrainedModel):\n","    def __init__(self, config):\n","        super().__init__(config)\n","        self.bert = BertModel(config)\n","        self.init_weights()\n","        self.features = config.hidden_size\n","\n","    def forward(\n","        self,\n","        input_ids=None,\n","        attention_mask=None,\n","        token_type_ids=None,\n","        position_ids=None,\n","        head_mask=None,\n","        inputs_embeds=None,\n","        labels=None,\n","    ):\n","\n","            bert_outputs = self.bert(\n","              input_ids,\n","              attention_mask=attention_mask,\n","              token_type_ids=token_type_ids,\n","              position_ids=position_ids,\n","              head_mask=head_mask,\n","              inputs_embeds=inputs_embeds,\n","            )\n","            pooled_output = bert_outputs[1]\n","\n","            return pooled_output"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EiVHnVrSBBNn","colab_type":"text"},"source":["## Main Model"]},{"cell_type":"code","metadata":{"id":"Ru0VPF2dat-F","colab_type":"code","colab":{}},"source":["class BertGCN(nn.Module):\n","  def __init__(self, hidden, vocabulary, n_grams, edges_mappings, edges_weights, count, num_classes, dropout_prob):\n","    super(BertGCN, self).__init__()\n","    self.bert = BertFeature.from_pretrained('bert-base-cased', output_attentions=False)\n","    self.gcn = GCNModel(hidden_size_node = hidden,\n","                            vocab = vocabulary,\n","                            n_gram = n_grams,\n","                            edges_matrix = edges_mappings,\n","                            edges_num = count,\n","                            trainable_edges = True, \n","                            pmi = edges_weights, \n","                            cuda = True\n","                            )\n","    self.num_classes = num_classes\n","    self.dropout = nn.Dropout(dropout_prob)\n","    self.bn1 = nn.BatchNorm1d(self.bert.features)\n","    self.relu1 = torch.nn.ReLU()\n","    self.relu2 = torch.nn.ReLU()\n","    \n","    self.bn2 = nn.BatchNorm1d(hidden)\n","    \n","    self.classifier = nn.Linear(self.bert.features + hidden, self.num_classes)\n","\n","  def forward(self, input_ids, attention_mask, input_gcn, sent_len, labels=None):\n","    bert_out = self.bert(input_ids, attention_mask)\n","    gcn_out = self.gcn(input_gcn, sent_len)\n","\n","    # return bert_out, gcn_out\n","\n","    # bert_out = self.bn1(bert_out)\n","    # gcn_out = self.bn2(gcn_out)\n","    \n","    # bert_out = self.relu1(bert_out)\n","    # gcn_out = self.relu2(gcn_out)\n","\n","    out = torch.cat((bert_out, gcn_out), 1)\n","    # pooled_output = self.dropout(out)\n","    logits = self.classifier(out)\n","\n","    outputs = (logits,)\n","\n","    if labels is not None:\n","        if self.num_classes == 1:\n","            loss_fct = MSELoss()\n","            loss = loss_fct(logits.view(-1), labels.view(-1))\n","        else:\n","            loss_fct = torch.nn.CrossEntropyLoss()\n","            loss = loss_fct(logits.view(-1, self.num_classes), labels.view(-1))\n","        outputs = (loss,) + outputs\n","    return outputs"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WrR6bjn8du_M","colab_type":"text"},"source":["## DEBUG"]},{"cell_type":"code","metadata":{"id":"zhCtvR35VZ0T","colab_type":"code","outputId":"9d6e4886-68dc-4120-a692-7e7c5cbac84e","colab":{"base_uri":"https://localhost:8080/","height":66,"referenced_widgets":["9ebf2289e76e4723b50fadc321eab9fd","6248f60279714fbd9f906c5a548dbaf6","61f4aea5de844f72861652d2e3bd3632","b813ed138af94fb6a0defbb21403be02","d2e1495b188642c885df5db556468624","54e1279395b34166902da4d939f39873","2c3f6f9fc1014218a18225858af2eb71","272da6549b324754ad70ac68e1a98b5c"]},"executionInfo":{"status":"ok","timestamp":1585053034463,"user_tz":-330,"elapsed":327248,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["edges_weights, edges_mappings, count = cal_PMI(train_data_helper, 5)"],"execution_count":25,"outputs":[{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"9ebf2289e76e4723b50fadc321eab9fd","version_minor":0,"version_major":2},"text/plain":["HBox(children=(IntProgress(value=0, max=17461), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"H7WXHTWvdw7N","colab_type":"code","colab":{}},"source":["# model = BertGCN(hidden = 200,\n","#                 vocabulary = train_data_helper.vocab,\n","#                 n_grams = 5,\n","#                 edges_mappings = edges_mappings,\n","#                 edges_weights = edges_weights, \n","#                 count = count, \n","#                 num_classes = 2, \n","#                 dropout_prob = 0.3\n","#                 )"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"colab_type":"text","id":"qCrL_HHYxQwa"},"source":["# Training"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"vs29Zck60rpB","outputId":"e41641e1-c147-4508-e820-49c53b2ee9c6","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585053034468,"user_tz":-330,"elapsed":323429,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n","device"],"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["device(type='cuda', index=0)"]},"metadata":{"tags":[]},"execution_count":26}]},{"cell_type":"code","metadata":{"colab_type":"code","id":"9mqC5yTxyV3-","colab":{}},"source":["from sklearn.utils.extmath import softmax\n","from sklearn.metrics import classification_report, f1_score\n","BATCH_SIZE = 32\n","\n","\n","def flat_accuracy(preds, labels):\n","    preds = softmax(preds)\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return np.sum(pred_flat == labels_flat) / len(labels_flat)\n","\n","\n","def flat_f1(preds, labels):\n","    preds = softmax(preds)\n","    pred_flat = np.argmax(preds, axis=1).flatten()\n","    labels_flat = labels.flatten()\n","    return f1_score(labels_flat, pred_flat)\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"KXZgwyjq0DMw","colab_type":"code","colab":{}},"source":["X_train_gcn = train_data_helper.content\n","X_train_len = train_data_helper.lengths\n","\n","X_dev_gcn = dev_data_helper.content\n","X_dev_len = dev_data_helper.lengths\n","\n","X_test_gcn = test_data_helper.content\n","X_test_len = test_data_helper.lengths"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"knqd-QH4x-Oy","colab_type":"code","colab":{}},"source":["X_train_gcn = np.array(X_train_gcn)\n","X_dev_gcn = np.array(X_dev_gcn)\n","X_test_gcn = np.array(X_test_gcn)\n","\n","X_train_len = np.array(X_train_len)\n","X_dev_len = np.array(X_dev_len)\n","X_test_len = np.array(X_test_len)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kxSLkhZk4r1K","colab_type":"code","colab":{}},"source":["X_train = torch.tensor(X_train)\n","X_train_masks = torch.tensor(X_train_masks)\n","X_train_gcn = torch.tensor(X_train_gcn)\n","X_train_len = torch.tensor(X_train_len)\n","y_train = torch.tensor(y_train)\n","\n","train_data = TensorDataset(X_train, X_train_masks, X_train_gcn, X_train_len, y_train)\n","train_sampler = SequentialSampler(train_data)\n","train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"g5N5FTqd5Bf2","colab_type":"code","colab":{}},"source":["X_dev = torch.tensor(X_dev)\n","X_dev_masks = torch.tensor(X_dev_masks)\n","X_dev_gcn = torch.tensor(X_dev_gcn)\n","X_dev_len = torch.tensor(X_dev_len)\n","y_dev = torch.tensor(y_dev)\n","\n","\n","dev_data = TensorDataset(X_dev, X_dev_masks, X_dev_gcn, X_dev_len, y_dev)\n","dev_sampler = SequentialSampler(dev_data)\n","dev_dataloader = DataLoader(dev_data, sampler=dev_sampler, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"P9GScsKOEiUT","colab_type":"code","colab":{}},"source":["X_test = torch.tensor(X_test)\n","X_test_masks = torch.tensor(X_test_masks)\n","X_test_gcn = torch.tensor(X_test_gcn)\n","X_test_len = torch.tensor(X_test_len)\n","\n","test_data = TensorDataset(X_test, X_test_masks, X_test_gcn, X_test_len)\n","test_sampler = SequentialSampler(test_data)\n","test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=BATCH_SIZE)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"d1IX4_ZwHzR3","colab_type":"text"},"source":["### Loop"]},{"cell_type":"code","metadata":{"colab_type":"code","id":"EZww_KS_w93w","outputId":"846a905f-351f-4f8a-f05a-d11f19bac6f0","colab":{"base_uri":"https://localhost:8080/","height":364}},"source":["from tqdm.notebook import tqdm\n","import sys\n","auto_model = None\n","\n","\n","del auto_model\n","auto_model = BertGCN(hidden = 200,\n","            vocabulary = train_data_helper.vocab,\n","            n_grams = 5,\n","            edges_mappings = edges_mappings,\n","            edges_weights = edges_weights, \n","            count = count, \n","            num_classes = 2, \n","            dropout_prob = 0.3\n","            )\n","\n","\n","auto_model.to(device)\n","\n","# Optimizer\n","num_total_steps = 1000\n","num_warmup_steps = 100\n","lr = 5e-6\n","param_optimizer = list(auto_model.named_parameters())\n","no_decay = ['bias', 'gamma', 'beta']\n","optimizer_grouped_parameters = [\n","  {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n","  'weight_decay_rate': 0.01},\n","  {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n","  'weight_decay_rate': 0.0}\n","]\n","optimizer = AdamW(optimizer_grouped_parameters, lr=lr)\n","\n","best_loss = None\n","\n","auto_model.train()  \n","tr_loss = 0\n","nb_tr_examples, nb_tr_steps = 0, 0\n","n_epochs = 5\n","\n","# Training Loop\n","for epoch in (range(n_epochs)):  \n","  auto_model.train()\n","  for step, batch in (enumerate(train_dataloader)):\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_input_gcn ,b_len, b_labels = batch\n","    optimizer.zero_grad()\n","    outputs = auto_model(b_input_ids, \n","                          b_input_mask, \n","                          b_input_gcn, \n","                          b_len, \n","                          b_labels)\n","\n","    loss, logits = outputs[:2]\n","    loss.backward()\n","    optimizer.step()\n","    \n","    tr_loss += loss.item()\n","    nb_tr_examples += b_input_ids.size(0)\n","    nb_tr_steps += 1\n","\n","\n","  # Validation Loop\n","  auto_model.eval()\n","  eval_loss, eval_accuracy = 0, 0\n","  nb_eval_steps, nb_eval_examples = 0, 0\n","\n","  yt, yp = [], []\n","  for batch in dev_dataloader:\n","    batch = tuple(t.to(device) for t in batch)\n","    b_input_ids, b_input_mask, b_input_gcn ,b_len, b_labels = batch\n","\n","    with torch.no_grad():\n","      outputs = auto_model(b_input_ids, \n","                            attention_mask=b_input_mask,\n","                            input_gcn = b_input_gcn,\n","                            sent_len = b_len,\n","                            labels= b_labels)        \n","      loss, logits = outputs[:2]\n","    logits = logits.detach().cpu().numpy()\n","\n","    preds = softmax(logits)\n","    pred_ids = np.argmax(preds, axis=1).flatten()\n","\n","    label_ids = b_labels.to('cpu').numpy()\n","\n","    eval_loss += loss.item()\n","    eval_accuracy += flat_accuracy(logits, label_ids)\n","\n","    yt = yt + label_ids.tolist()\n","    yp = yp + pred_ids.tolist()\n","\n","    nb_eval_steps +=1\n","        \n","  print(\"Epoch {} | Train loss: {} | Validation Loss: {} \".format(epoch,\n","                                                                    tr_loss/nb_tr_steps,\n","                                                                    eval_loss/nb_eval_steps, \n","                                                                  ))\n","  if best_loss == None or best_loss > eval_loss/nb_eval_steps:\n","    best_loss = eval_loss/nb_eval_steps\n","    torch.save(auto_model.state_dict(), 'models/check_bertgcn.pth')\n","    print(f'Saving model')\n","\n","\n","print(classification_report(yt, yp))   "],"execution_count":0,"outputs":[{"output_type":"stream","text":["873034\n","torch.Size([873034, 1])\n","Epoch 0 | Train loss: 0.4278146782855848 | Validation Loss: 0.4144361753154684 \n","Saving model\n","Epoch 1 | Train loss: 0.3749028979613012 | Validation Loss: 0.3969629853963852 \n","Saving model\n","Epoch 2 | Train loss: 0.34298959613455887 | Validation Loss: 0.3737640215290917 \n","Saving model\n","Epoch 3 | Train loss: 0.3172001071980448 | Validation Loss: 0.35195665723747677 \n","Saving model\n","Epoch 4 | Train loss: 0.294219728980227 | Validation Loss: 0.3822715911600325 \n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.97      0.92       582\n","           1       0.91      0.69      0.78       272\n","\n","    accuracy                           0.88       854\n","   macro avg       0.89      0.83      0.85       854\n","weighted avg       0.88      0.88      0.87       854\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ZNQ5nQwKftdN","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"7d1a90c3-bd3d-4441-b379-cf75db651e53","executionInfo":{"status":"ok","timestamp":1585053198412,"user_tz":-330,"elapsed":49854,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["auto_model = BertGCN(hidden = 200,\n","            vocabulary = train_data_helper.vocab,\n","            n_grams = 5,\n","            edges_mappings = edges_mappings,\n","            edges_weights = edges_weights, \n","            count = count, \n","            num_classes = 2, \n","            dropout_prob = 0.3\n","            )\n","\n","\n","\n","auto_model.load_state_dict(torch.load('models/check_bertgcn.pth'))\n","auto_model.to(device)\n","auto_model.eval()\n","print('Loading best model')\n","\n","yt, yp, p = [], [], []\n","for batch in dev_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","  b_input_ids, b_input_mask, b_input_gcn ,b_len, b_labels = batch\n","\n","  with torch.no_grad():\n","    outputs = auto_model(b_input_ids, \n","                            attention_mask=b_input_mask,\n","                            input_gcn = b_input_gcn,\n","                            sent_len = b_len,\n","                            labels= b_labels)          \n","    loss, logits = outputs[:2]\n","  logits = logits.detach().cpu().numpy()\n","  preds = softmax(logits)\n","\n","  pred_ids = np.argmax(preds, axis=1).flatten()\n","  label_ids = b_labels.to('cpu').numpy()\n","\n","  p = p + preds[:,1].tolist()\n","  yt = yt + label_ids.tolist()\n","  yp = yp + pred_ids.tolist()"],"execution_count":34,"outputs":[{"output_type":"stream","text":["873034\n","torch.Size([873034, 1])\n","Loading best model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hprSG3d_fxN7","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":206},"outputId":"d27a2e02-142f-4024-af84-40365820bfdb","executionInfo":{"status":"ok","timestamp":1585053206799,"user_tz":-330,"elapsed":1331,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["dev_df['Probability'] = p\n","dev_df['Predicted'] = yp\n","dev_df['Loss'] = -dev_df['Label']*np.log2(dev_df['Probability']) - (1-dev_df['Label'])*np.log2(1-dev_df['Probability'])\n","dev_df = dev_df.sort_values(by='Loss', axis=0, ascending=False)\n","dev_df.head()"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Subject</th>\n","      <th>Sentence</th>\n","      <th>Label</th>\n","      <th>Probability</th>\n","      <th>Predicted</th>\n","      <th>Loss</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>653</th>\n","      <td>government</td>\n","      <td>”United States v. Miller , 307 U.S. 174 ( 1939...</td>\n","      <td>1</td>\n","      <td>0.008916</td>\n","      <td>0</td>\n","      <td>6.809331</td>\n","    </tr>\n","    <tr>\n","      <th>40</th>\n","      <td>biology</td>\n","      <td>Pathogens include bacteria , protists , fungi ...</td>\n","      <td>1</td>\n","      <td>0.009523</td>\n","      <td>0</td>\n","      <td>6.714331</td>\n","    </tr>\n","    <tr>\n","      <th>570</th>\n","      <td>sociology</td>\n","      <td>While pastoral and horticultural societies use...</td>\n","      <td>1</td>\n","      <td>0.010113</td>\n","      <td>0</td>\n","      <td>6.627664</td>\n","    </tr>\n","    <tr>\n","      <th>702</th>\n","      <td>government</td>\n","      <td>Starting in New York in 1790 , the early Supre...</td>\n","      <td>1</td>\n","      <td>0.010170</td>\n","      <td>0</td>\n","      <td>6.619555</td>\n","    </tr>\n","    <tr>\n","      <th>706</th>\n","      <td>government</td>\n","      <td>The practice of judicial review enabled the la...</td>\n","      <td>1</td>\n","      <td>0.012451</td>\n","      <td>0</td>\n","      <td>6.327596</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["        Subject  ...      Loss\n","653  government  ...  6.809331\n","40      biology  ...  6.714331\n","570   sociology  ...  6.627664\n","702  government  ...  6.619555\n","706  government  ...  6.327596\n","\n","[5 rows x 6 columns]"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"g5V3r-lnf1jG","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":211},"outputId":"56fb6f43-a61b-4c95-eca2-3d86d84a7cbc","executionInfo":{"status":"ok","timestamp":1585053216008,"user_tz":-330,"elapsed":1030,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["c = 10\n","for i in dev_df['Sentence']:\n","  print(i)\n","  c-=1\n","  if c==0:\n","    break"],"execution_count":36,"outputs":[{"output_type":"stream","text":["”United States v. Miller , 307 U.S. 174 ( 1939 ) .\n","Pathogens include bacteria , protists , fungi and other infectious organisms .\n","While pastoral and horticultural societies used small , temporary tools such as digging sticks or hoes , agricultural societies relied on permanent tools for survival .\n","Starting in New York in 1790 , the early Supreme Court focused on establishing its rules and procedures and perhaps trying to carve its place as the new government ’s third branch .\n","The practice of judicial review enabled the law ’s critics to exercise this opportunity , even though their hopes were ultimately dashed when , by a narrow 5 – 4 margin , the Supreme Court upheld the health care law as a constitutional extension of Congress ’s power to tax .\n","Radical Whigs favored broadening the popular participation in political life and pushed for democracy .\n","Perhaps the greatest real estate deal in American history , the Louisiana Purchase greatly enhanced the Jeffersonian vision of the United States as an agrarian republic in which yeomen farmers worked the land .\n","These rules are special cases of the laws of conservation of charge and conservation of energy .\n","The grandfather clause exempted those who had been allowed to vote in that state prior to the Civil War and their descendants from literacy and understanding tests . Keyssar , 112 .\n","First , specialization in a particular small job allows workers to focus on the parts of the production process where they have an advantage .\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"VwhjAWFGiU8I","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":69},"outputId":"f88aa9f9-fb23-4457-e9c0-bdd43fc6b007","executionInfo":{"status":"ok","timestamp":1585053300591,"user_tz":-330,"elapsed":1063,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["dev_df.loc[706, ['Sentence', 'Loss']]"],"execution_count":39,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sentence    The practice of judicial review enabled the la...\n","Loss                                                   6.3276\n","Name: 706, dtype: object"]},"metadata":{"tags":[]},"execution_count":39}]},{"cell_type":"code","metadata":{"id":"l1j2EMBdirHb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":52},"outputId":"c9413286-1266-440d-bf10-00bc6b2312f0","executionInfo":{"status":"ok","timestamp":1585057657420,"user_tz":-330,"elapsed":1188,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["from sklearn.metrics import confusion_matrix, f1_score\n","confusion_matrix(yt, yp), f1_score(yt, yp)"],"execution_count":42,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(array([[565,  17],\n","        [ 87, 185]]), 0.7805907172995781)"]},"metadata":{"tags":[]},"execution_count":42}]},{"cell_type":"markdown","metadata":{"id":"EgIE6hwo81DX","colab_type":"text"},"source":["# Test Predictions"]},{"cell_type":"code","metadata":{"id":"layS6IlIQTtA","colab_type":"code","outputId":"5787fce6-49bb-4334-95e0-5e5e54a2b449","colab":{"base_uri":"https://localhost:8080/","height":34},"executionInfo":{"status":"ok","timestamp":1585053410275,"user_tz":-330,"elapsed":14949,"user":{"displayName":"Priyanshu Kumar","photoUrl":"","userId":"17613516997044266683"}}},"source":["test_preds = []\n","auto_model.load_state_dict(torch.load('models/check_bertgcn.pth'))\n","auto_model.eval()\n","print('Loading best model')\n","\n","for batch in test_dataloader:\n","  batch = tuple(t.to(device) for t in batch)\n","  b_input_ids, b_input_mask, b_input_gcn ,b_len = batch\n","\n","  with torch.no_grad():\n","    outputs = auto_model(b_input_ids, \n","                          b_input_mask,\n","                          b_input_gcn,\n","                          b_len\n","                        )        \n","    logits = outputs[0]\n","  logits = logits.detach().cpu().numpy()\n","  preds = softmax(logits)[:, 1]        \n","  test_preds = test_preds + preds.tolist()\n","\n"],"execution_count":41,"outputs":[{"output_type":"stream","text":["Loading best model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"gZud6s5wQTGD","colab_type":"code","outputId":"c52fa24e-e09c-4af9-f777-20d841b4f715","colab":{"base_uri":"https://localhost:8080/","height":173}},"source":["test_df['Probability'] = test_preds\n","test_df['Probability'].describe()"],"execution_count":0,"outputs":[{"output_type":"execute_result","data":{"text/plain":["count    859.000000\n","mean       0.231181\n","std        0.338427\n","min        0.005361\n","25%        0.010326\n","50%        0.029999\n","75%        0.328995\n","max        0.980175\n","Name: Probability, dtype: float64"]},"metadata":{"tags":[]},"execution_count":45}]},{"cell_type":"code","metadata":{"id":"W6FTw6UqzliW","colab_type":"code","colab":{}},"source":["test_df.to_csv('sub/submission_bert_gcn_final.csv', index=False)"],"execution_count":0,"outputs":[]}]}